"""
Task 4.2: ê³ ê¸‰ ì²­í‚¹ ë° í† í°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
3ê°€ì§€ ì²­í‚¹ ì „ëµì˜ ì„±ëŠ¥ê³¼ ì •í™•ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""
import asyncio
import os
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple

from dotenv import load_dotenv

try:
    from services.chunking_service import (
        AdvancedChunkingService, 
        ChunkingStrategy, 
        ChunkingConfig
    )
    CHUNKING_SERVICE_AVAILABLE = True
    print("âœ… ì²­í‚¹ ì„œë¹„ìŠ¤ import ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ì²­í‚¹ ì„œë¹„ìŠ¤ import ì‹¤íŒ¨: {e}")
    CHUNKING_SERVICE_AVAILABLE = False
from agents.base import ProcessedChunk

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class ChunkingTestReport:
    """ì²­í‚¹ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ"""
    
    def __init__(self):
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.report_data = {
            "metadata": {
                "timestamp": self.timestamp,
                "test_type": "advanced_chunking_analysis"
            },
            "strategy_tests": {},
            "performance_comparison": {},
            "quality_metrics": {},
            "overall_status": "FAILED",
            "error_message": None
        }
        self.console_output = []

    def log_console(self, message: str):
        """ì½˜ì†” ì¶œë ¥ì„ ë¡œê·¸ì— ì €ì¥"""
        self.console_output.append(message)
        print(message)

    def add_strategy_test(self, strategy: str, result: Dict[str, Any]):
        """ì „ëµë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶”ê°€"""
        self.report_data["strategy_tests"][strategy] = result

    def add_performance_comparison(self, comparison: Dict[str, Any]):
        """ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì¶”ê°€"""
        self.report_data["performance_comparison"] = comparison

    def add_quality_metrics(self, metrics: Dict[str, Any]):
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ê°€"""
        self.report_data["quality_metrics"] = metrics

    def set_overall_status(self, status: str, error_message: str = None):
        """ì „ì²´ ìƒíƒœ ì„¤ì •"""
        self.report_data["overall_status"] = status
        self.report_data["error_message"] = error_message

    def save_reports(self):
        """ë³´ê³ ì„œ ì €ì¥"""
        reports_dir = Path("reports/chunking_service")
        reports_dir.mkdir(parents=True, exist_ok=True)

        base_filename = f"chunking_service_report_{self.timestamp}"

        # JSON ë³´ê³ ì„œ
        json_file = reports_dir / f"{base_filename}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.report_data, f, indent=2, ensure_ascii=False, default=str)

        # í…ìŠ¤íŠ¸ ìš”ì•½
        txt_file = reports_dir / f"{base_filename}_summary.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ê³ ê¸‰ ì²­í‚¹ ë° í† í°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"ğŸ• í…ŒìŠ¤íŠ¸ ì‹œê°„: {self.timestamp}\n")
            f.write(f"âœ… ì „ì²´ ìƒíƒœ: {self.report_data['overall_status']}\n\n")

            f.write("ğŸ“Š ì „ëµë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n")
            for strategy, result in self.report_data["strategy_tests"].items():
                status = "âœ…" if result.get("success", False) else "âŒ"
                f.write(f"   {status} {strategy}: {result.get('chunk_count', 0)}ê°œ ì²­í¬\n")
            f.write("\n")

            if self.report_data["performance_comparison"]:
                f.write("âš¡ ì„±ëŠ¥ ë¹„êµ:\n")
                perf = self.report_data["performance_comparison"]
                for strategy, timing in perf.get("processing_times", {}).items():
                    f.write(f"   - {strategy}: {timing:.3f}ì´ˆ\n")
            f.write("\n")

            if self.report_data["quality_metrics"]:
                f.write("ğŸ¯ í’ˆì§ˆ ë©”íŠ¸ë¦­:\n")
                quality = self.report_data["quality_metrics"]
                for metric, value in quality.items():
                    f.write(f"   - {metric}: {value}\n")
            f.write("\n")

            f.write("=" * 80 + "\n")
            f.write("ì½˜ì†” ì¶œë ¥ ë¡œê·¸:\n")
            f.write("=" * 80 + "\n")
            for line in self.console_output:
                f.write(line + "\n")

        return {"json_report": str(json_file), "txt_summary": str(txt_file)}

def create_sample_insurance_text() -> str:
    """í…ŒìŠ¤íŠ¸ìš© ë³´í—˜ì•½ê´€ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìƒì„±"""
    return """
ì œ1ì¥ ì´ì¹™

ì œ1ì¡° (ëª©ì ) ì´ ì•½ê´€ì€ ë³´í—˜íšŒì‚¬ì™€ ë³´í—˜ê³„ì•½ì ê°„ì˜ ê¶Œë¦¬ì™€ ì˜ë¬´ë¥¼ ê·œì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë³´í—˜ì•½ê´€ì€ ë³´í—˜ê³„ì•½ì˜ ê¸°ë³¸ ì¡°ê±´ì„ ëª…ì‹œí•˜ë©°, ì–‘ ë‹¹ì‚¬ìê°€ ì¤€ìˆ˜í•´ì•¼ í•  ì‚¬í•­ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.

ì œ2ì¡° (ì •ì˜) ì´ ì•½ê´€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ì •ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
1. ë³´í—˜ê³„ì•½ì: ë³´í—˜íšŒì‚¬ì™€ ë³´í—˜ê³„ì•½ì„ ì²´ê²°í•˜ê³  ë³´í—˜ë£Œë¥¼ ë‚©ì…í•  ì˜ë¬´ë¥¼ ì§€ëŠ” ìë¥¼ ë§í•©ë‹ˆë‹¤.
2. í”¼ë³´í—˜ì: ë³´í—˜ì‚¬ê³ ì˜ ëŒ€ìƒì´ ë˜ëŠ” ìë¥¼ ë§í•©ë‹ˆë‹¤.
3. ë³´í—˜ê¸ˆì•¡: ë³´í—˜íšŒì‚¬ê°€ ë³´í—˜ì‚¬ê³  ë°œìƒ ì‹œ ì§€ê¸‰í•  ìˆ˜ ìˆëŠ” ë³´ìƒì˜ ìµœê³  í•œë„ì•¡ì„ ë§í•©ë‹ˆë‹¤.
4. ë³´í—˜ë£Œ: ë³´í—˜ê³„ì•½ì— ë”°ë¼ ë³´í—˜ê³„ì•½ìê°€ ë³´í—˜íšŒì‚¬ì— ë‚©ì…í•˜ëŠ” ëŒ€ê°€ë¥¼ ë§í•©ë‹ˆë‹¤.

ì œ3ì¡° (ë³´í—˜ê³„ì•½ì˜ ì„±ë¦½) ë³´í—˜ê³„ì•½ì€ ë³´í—˜ê³„ì•½ìì˜ ì²­ì•½ê³¼ ë³´í—˜íšŒì‚¬ì˜ ìŠ¹ë‚™ìœ¼ë¡œ ì„±ë¦½ë©ë‹ˆë‹¤. ë³´í—˜íšŒì‚¬ëŠ” ì²­ì•½ì„ ë°›ì€ ë‚ ë¶€í„° 30ì¼ ì´ë‚´ì— ìŠ¹ë‚™ ë˜ëŠ” ê±°ì ˆì˜ ì˜ì‚¬í‘œì‹œë¥¼ í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.

ì œ2ì¥ ë³´í—˜ë£Œì˜ ë‚©ì…

ì œ4ì¡° (ë³´í—˜ë£Œ ë‚©ì… ë°©ë²•) ë³´í—˜ë£ŒëŠ” ê³„ì•½ìê°€ ì„ íƒí•œ ë°©ë²•ì— ë”°ë¼ ë‚©ì…í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.
ê°€. ì¼ì‹œë‚©: ë³´í—˜ë£Œ ì „ì•¡ì„ í•œ ë²ˆì— ë‚©ì…í•˜ëŠ” ë°©ë²•
ë‚˜. ì›”ë‚©: ë§¤ì›” ë¶„í• í•˜ì—¬ ë‚©ì…í•˜ëŠ” ë°©ë²•
ë‹¤. ì—°ë‚©: ë§¤ë…„ ë¶„í• í•˜ì—¬ ë‚©ì…í•˜ëŠ” ë°©ë²•

ì œ5ì¡° (ë³´í—˜ë£Œ ì—°ì²´ ì‹œ ì¡°ì¹˜) ë³´í—˜ë£Œ ë‚©ì…ì´ ì—°ì²´ëœ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì¹˜ë¥¼ ì·¨í•©ë‹ˆë‹¤.
1. 14ì¼ê°„ì˜ ìœ ì˜ˆê¸°ê°„ì„ ì œê³µí•©ë‹ˆë‹¤.
2. ìœ ì˜ˆê¸°ê°„ ë‚´ ë‚©ì…í•˜ì§€ ì•Šì„ ê²½ìš° ë³´í—˜ê³„ì•½ì´ ì‹¤íš¨ë©ë‹ˆë‹¤.
3. ì‹¤íš¨ëœ ê³„ì•½ì€ 2ë…„ ì´ë‚´ì— ë¶€í™œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì œ3ì¥ ë³´í—˜ê¸ˆ ì§€ê¸‰

ì œ6ì¡° (ë³´í—˜ê¸ˆ ì§€ê¸‰ ì‚¬ìœ ) ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê²½ìš° ë³´í—˜ê¸ˆì„ ì§€ê¸‰í•©ë‹ˆë‹¤.
1. í”¼ë³´í—˜ìê°€ ì§ˆë³‘ ë˜ëŠ” ìƒí•´ë¡œ ì…ì›í•œ ê²½ìš°
2. í”¼ë³´í—˜ìê°€ ìˆ˜ìˆ ì„ ë°›ì€ ê²½ìš°  
3. í”¼ë³´í—˜ìê°€ ì§„ë‹¨í™•ì •ì„ ë°›ì€ ê²½ìš°

ì œ7ì¡° (ë³´í—˜ê¸ˆ ì§€ê¸‰ ì ˆì°¨) ë³´í—˜ê¸ˆ ì²­êµ¬ ì‹œ ë‹¤ìŒ ì„œë¥˜ë¥¼ ì œì¶œí•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
- ë³´í—˜ê¸ˆ ì²­êµ¬ì„œ
- ì§„ë‹¨ì„œ ë˜ëŠ” ì†Œê²¬ì„œ
- ì…ì›í™•ì¸ì„œ (ì…ì› ì‹œ)
- ìˆ˜ìˆ í™•ì¸ì„œ (ìˆ˜ìˆ  ì‹œ)
- ê¸°íƒ€ ë³´í—˜íšŒì‚¬ê°€ ìš”êµ¬í•˜ëŠ” ì„œë¥˜

ì œ8ì¡° (ë©´ì±…ì‚¬í•­) ë‹¤ìŒì˜ ê²½ìš°ì—ëŠ” ë³´í—˜ê¸ˆì„ ì§€ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
1. ê³ ì˜ ë˜ëŠ” ì¤‘ê³¼ì‹¤ë¡œ ì¸í•œ ì‚¬ê³ 
2. ìŒì£¼ìš´ì „ìœ¼ë¡œ ì¸í•œ ì‚¬ê³ 
3. ì „ìŸ, í­ë™, ë‚´ë€ ë“±ìœ¼ë¡œ ì¸í•œ ì‚¬ê³ 
4. ê¸°íƒ€ ì•½ê´€ì—ì„œ ì •í•œ ë©´ì±…ì‚¬ìœ 
"""

async def test_chunking_strategies():
    """3ê°€ì§€ ì²­í‚¹ ì „ëµ í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("ì²­í‚¹ ì „ëµë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    report = ChunkingTestReport()
    sample_text = create_sample_insurance_text()
    
    strategies = [
        ChunkingStrategy.FIXED_SIZE,
        ChunkingStrategy.CONTENT_AWARE,
        ChunkingStrategy.SEMANTIC
    ]
    
    strategy_results = {}
    processing_times = {}
    
    for strategy in strategies:
        try:
            report.log_console(f"\nğŸ“Š ì „ëµ: {strategy.value}")
            
            # ì²­í‚¹ ì„œë¹„ìŠ¤ ìƒì„±
            config = ChunkingConfig(
                strategy=strategy,
                chunk_size=200,
                overlap_ratio=0.15,
                preserve_article_boundaries=True
            )
            service = AdvancedChunkingService(config)
            
            # ì²­í‚¹ ì‹¤í–‰ ë° ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            chunks = await service.chunk_text(sample_text, {"page_number": 1})
            processing_time = time.time() - start_time
            
            processing_times[strategy.value] = processing_time
            
            # í†µê³„ ìƒì„±
            stats = service.get_chunking_stats(chunks)
            
            report.log_console(f"   ì²­í¬ ìˆ˜: {stats['total_chunks']}")
            report.log_console(f"   í‰ê·  í† í°: {stats['avg_tokens_per_chunk']:.1f}")
            report.log_console(f"   í† í° ë²”ìœ„: {stats['min_tokens']}-{stats['max_tokens']}")
            report.log_console(f"   ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
            
            # ì²­í¬ í’ˆì§ˆ ê²€ì¦
            quality_score = _evaluate_chunk_quality(chunks, strategy)
            report.log_console(f"   í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")
            
            strategy_results[strategy.value] = {
                "success": True,
                "chunk_count": stats['total_chunks'],
                "avg_tokens": stats['avg_tokens_per_chunk'],
                "token_range": f"{stats['min_tokens']}-{stats['max_tokens']}",
                "total_tokens": stats['total_tokens'],
                "processing_time": processing_time,
                "quality_score": quality_score,
                "stats": stats
            }
            
            report.add_strategy_test(strategy.value, strategy_results[strategy.value])
            
        except Exception as e:
            error_msg = f"ì „ëµ {strategy.value} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            report.log_console(f"   âŒ {error_msg}")
            
            strategy_results[strategy.value] = {
                "success": False,
                "error": str(e),
                "chunk_count": 0,
                "processing_time": 0,
                "quality_score": 0
            }
            
            report.add_strategy_test(strategy.value, strategy_results[strategy.value])
    
    # ì„±ëŠ¥ ë¹„êµ
    performance_comparison = {
        "processing_times": processing_times,
        "fastest_strategy": min(processing_times, key=processing_times.get) if processing_times else None,
        "slowest_strategy": max(processing_times, key=processing_times.get) if processing_times else None
    }
    
    report.add_performance_comparison(performance_comparison)
    
    return report, strategy_results

def _evaluate_chunk_quality(chunks: List[ProcessedChunk], strategy: ChunkingStrategy) -> float:
    """ì²­í‚¹ í’ˆì§ˆ í‰ê°€"""
    if not chunks:
        return 0.0
    
    quality_score = 100.0
    
    # 1. í† í° í¬ê¸° ì¼ê´€ì„± (Â±5% í—ˆìš©)
    target_size = 200
    token_counts = [chunk["metadata"]["token_count"] for chunk in chunks]
    size_variance = sum(abs(count - target_size) for count in token_counts) / len(token_counts)
    size_penalty = min(30, size_variance / target_size * 100)
    quality_score -= size_penalty
    
    # 2. ìµœì†Œ/ìµœëŒ€ í¬ê¸° ìœ„ë°˜
    min_violations = sum(1 for count in token_counts if count < 50)
    max_violations = sum(1 for count in token_counts if count > 300)
    violation_penalty = (min_violations + max_violations) / len(chunks) * 20
    quality_score -= violation_penalty
    
    # 3. ì „ëµë³„ ì¶”ê°€ í‰ê°€
    if strategy == ChunkingStrategy.CONTENT_AWARE:
        # ì¡°í•­ ê²½ê³„ ë³´ì¡´ í‰ê°€
        article_preserved_chunks = sum(1 for chunk in chunks 
                                     if chunk["metadata"].get("article_title"))
        if article_preserved_chunks > 0:
            quality_score += 10  # ë³´ë„ˆìŠ¤
    
    elif strategy == ChunkingStrategy.SEMANTIC:
        # ì£¼ì œ ì¼ê´€ì„± í‰ê°€
        topic_chunks = sum(1 for chunk in chunks 
                          if chunk["metadata"].get("semantic_topic"))
        if topic_chunks > len(chunks) * 0.8:
            quality_score += 10  # ë³´ë„ˆìŠ¤
    
    return max(0, min(100, quality_score))

async def test_article_boundary_preservation():
    """ì¡°í•­ ê²½ê³„ ë³´ì¡´ í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 60)
    logger.info("ì¡°í•­ ê²½ê³„ ë³´ì¡´ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 60)
    
    report = ChunkingTestReport()
    sample_text = create_sample_insurance_text()
    
    # Content-aware ì „ëµìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    config = ChunkingConfig(
        strategy=ChunkingStrategy.CONTENT_AWARE,
        chunk_size=200,
        preserve_article_boundaries=True
    )
    service = AdvancedChunkingService(config)
    
    try:
        chunks = await service.chunk_text(sample_text)
        
        # ì¡°í•­ ê²½ê³„ ë¶„ì„
        article_chunks = [chunk for chunk in chunks 
                         if chunk["metadata"].get("article_title")]
        
        report.log_console(f"ì „ì²´ ì²­í¬ ìˆ˜: {len(chunks)}")
        report.log_console(f"ì¡°í•­ ê²½ê³„ ë³´ì¡´ ì²­í¬: {len(article_chunks)}")
        report.log_console(f"ì¡°í•­ ë³´ì¡´ìœ¨: {len(article_chunks)/len(chunks)*100:.1f}%")
        
        # ì¡°í•­ë³„ ìƒì„¸ ë¶„ì„
        articles_found = set()
        for chunk in article_chunks:
            article_title = chunk["metadata"].get("article_title", "")
            if article_title:
                articles_found.add(article_title)
        
        report.log_console(f"ë°œê²¬ëœ ì¡°í•­ ìˆ˜: {len(articles_found)}")
        for article in sorted(articles_found):
            report.log_console(f"   - {article}")
        
        return True
        
    except Exception as e:
        report.log_console(f"âŒ ì¡°í•­ ê²½ê³„ ë³´ì¡´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

async def test_token_accuracy():
    """í† í° ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 60)
    logger.info("í† í° ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸")
    logger.info("=" * 60)
    
    report = ChunkingTestReport()
    
    try:
        # tiktoken ì§ì ‘ ì‚¬ìš©
        import tiktoken
        tokenizer = tiktoken.get_encoding("cl100k_base")
        
        test_texts = [
            "ë³´í—˜ì•½ê´€ ì œ1ì¡° ëª©ì ",
            "ë³´í—˜ê³„ì•½ìëŠ” ë³´í—˜ë£Œë¥¼ ë‚©ì…í•  ì˜ë¬´ê°€ ìˆìŠµë‹ˆë‹¤.",
            "ì œ2ì¡° (ì •ì˜) ì´ ì•½ê´€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ì •ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
        ]
        
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED_SIZE, chunk_size=200)
        service = AdvancedChunkingService(config)
        
        total_accuracy = 0
        
        for i, text in enumerate(test_texts):
            # tiktokenìœ¼ë¡œ ì§ì ‘ ê³„ì‚°
            actual_tokens = len(tokenizer.encode(text))
            
            # ì„œë¹„ìŠ¤ë¡œ ê³„ì‚° (í…ŒìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€)
            test_metadata = {"source": "í† í°_í…ŒìŠ¤íŠ¸", "page_number": 1}
            chunks = await service.chunk_text(text, test_metadata)
            if chunks:
                service_tokens = chunks[0]["metadata"]["token_count"]
                accuracy = (1 - abs(actual_tokens - service_tokens) / actual_tokens) * 100
            else:
                accuracy = 0
            
            total_accuracy += accuracy
            
            report.log_console(f"í…ŒìŠ¤íŠ¸ {i+1}:")
            report.log_console(f"   ì‹¤ì œ í† í°: {actual_tokens}")
            report.log_console(f"   ì„œë¹„ìŠ¤ í† í°: {service_tokens if chunks else 0}")
            report.log_console(f"   ì •í™•ë„: {accuracy:.1f}%")
        
        avg_accuracy = total_accuracy / len(test_texts)
        report.log_console(f"\ní‰ê·  í† í° ê³„ì‚° ì •í™•ë„: {avg_accuracy:.1f}%")
        
        return avg_accuracy > 95.0
        
    except ImportError:
        report.log_console("âš ï¸ tiktokenì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í† í° ì •í™•ì„± í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return True
    except Exception as e:
        report.log_console(f"âŒ í† í° ì •í™•ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("=" * 80)
    logger.info("Task 4.2: ê³ ê¸‰ ì²­í‚¹ ë° í† í°í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 80)
    
    overall_report = ChunkingTestReport()
    
    try:
        # 1. ì²­í‚¹ ì „ëµë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        strategy_report, strategy_results = await test_chunking_strategies()
        overall_report.report_data["strategy_tests"] = strategy_report.report_data["strategy_tests"]
        overall_report.report_data["performance_comparison"] = strategy_report.report_data["performance_comparison"]
        overall_report.console_output.extend(strategy_report.console_output)
        
        # 2. ì¡°í•­ ê²½ê³„ ë³´ì¡´ í…ŒìŠ¤íŠ¸
        boundary_success = await test_article_boundary_preservation()
        
        # 3. í† í° ê³„ì‚° ì •í™•ì„± í…ŒìŠ¤íŠ¸
        token_accuracy_success = await test_token_accuracy()
        
        # ì „ì²´ ê²°ê³¼ í‰ê°€
        strategy_success = all(result.get("success", False) 
                              for result in strategy_results.values())
        
        overall_success = strategy_success and boundary_success and token_accuracy_success
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        if strategy_success:
            avg_quality = sum(result.get("quality_score", 0) 
                            for result in strategy_results.values()) / len(strategy_results)
            fastest_time = min(result.get("processing_time", float('inf')) 
                             for result in strategy_results.values())
            
            quality_metrics = {
                "average_quality_score": avg_quality,
                "fastest_processing_time": fastest_time,
                "boundary_preservation": boundary_success,
                "token_accuracy": token_accuracy_success,
                "strategies_tested": len(strategy_results)
            }
            overall_report.add_quality_metrics(quality_metrics)
        
        overall_report.log_console("\n" + "=" * 80)
        overall_report.log_console("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        overall_report.log_console("=" * 80)
        overall_report.log_console(f"ì²­í‚¹ ì „ëµ í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if strategy_success else 'âŒ ì‹¤íŒ¨'}")
        overall_report.log_console(f"ì¡°í•­ ê²½ê³„ ë³´ì¡´: {'âœ… ì„±ê³µ' if boundary_success else 'âŒ ì‹¤íŒ¨'}")
        overall_report.log_console(f"í† í° ê³„ì‚° ì •í™•ì„±: {'âœ… ì„±ê³µ' if token_accuracy_success else 'âŒ ì‹¤íŒ¨'}")
        overall_report.log_console(f"ì „ì²´ í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if overall_success else 'âŒ ì‹¤íŒ¨'}")
        
        if strategy_success:
            overall_report.log_console(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.1f}/100")
            overall_report.log_console(f"ìµœê³  ì„±ëŠ¥: {fastest_time:.3f}ì´ˆ")
        
        overall_report.set_overall_status("SUCCESS" if overall_success else "FAILED")
        
        # ë³´ê³ ì„œ ì €ì¥
        overall_report.log_console("\nğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì¤‘...")
        saved_files = overall_report.save_reports()
        overall_report.log_console("âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ!")
        overall_report.log_console(f"   - JSON ë³´ê³ ì„œ: {saved_files['json_report']}")
        overall_report.log_console(f"   - TXT ìš”ì•½: {saved_files['txt_summary']}")
        
    except Exception as e:
        error_msg = f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
        logger.error(error_msg, exc_info=True)
        overall_report.log_console(f"âŒ {error_msg}")
        overall_report.set_overall_status("FAILED", error_msg)
        overall_report.save_reports()

    logger.info("\n" + "=" * 80)
    logger.info("Task 4.2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("=" * 80)

if __name__ == "__main__":
    asyncio.run(main())
