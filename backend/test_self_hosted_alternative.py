#!/usr/bin/env python3
"""
Self-hosted LangFuse ëŒ€ì•ˆ í…ŒìŠ¤íŠ¸
Docker ì—†ì´ ë¡œì»¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
"""
import asyncio
import os
import sys
import logging
from datetime import datetime
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_local_monitoring_complete():
    """ë¡œì»¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ì „ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ğŸ  ë¡œì»¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ì „ í…ŒìŠ¤íŠ¸")
    print("   (Self-hosted LangFuse ëŒ€ì•ˆ)")
    print("=" * 60)
    
    try:
        # ë¡œì»¬ ëª¨ë‹ˆí„° ì§ì ‘ ì‚¬ìš© (LangFuse ìš°íšŒ)
        from services.local_monitor import local_monitor
        
        print(f"âœ… ë¡œì»¬ ëª¨ë‹ˆí„° í™œì„±í™”: {local_monitor.enabled}")
        print(f"âœ… ë¡œê·¸ ë””ë ‰í† ë¦¬: {local_monitor.log_dir}")
        
        # ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜
        print("\nğŸ“Š ë³µì¡í•œ PDF ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜...")
        
        # 1. PDF ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
        async with local_monitor.trace_workflow(
            "pdf_processing_pipeline",
            {
                "document": "sample_insurance_policy.pdf",
                "file_size": "2.5MB",
                "pages": 45,
                "language": "korean"
            }
        ) as pdf_trace:
            print("âœ… PDF ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            
            # 1.1 PDF ë¶„ì„ ì—ì´ì „íŠ¸
            pdf_analyzer = await local_monitor.trace_agent_execution(
                "pdf_analyzer",
                {
                    "input_file": "sample_insurance_policy.pdf",
                    "analysis_type": "structure_detection"
                },
                pdf_trace
            )
            
            await asyncio.sleep(0.2)  # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
            
            await local_monitor.update_agent_result(
                pdf_analyzer,
                {
                    "has_text_layer": True,
                    "table_count": 8,
                    "image_count": 3,
                    "total_pages": 45,
                    "scan_quality": "high"
                },
                0.2,
                "completed"
            )
            print("  âœ… PDF ë¶„ì„ ì™„ë£Œ")
            
            # 1.2 í…ìŠ¤íŠ¸ ì¶”ì¶œ ì—ì´ì „íŠ¸
            text_extractor = await local_monitor.trace_agent_execution(
                "text_extractor",
                {
                    "extraction_method": "pdfplumber_primary",
                    "fallback_ocr": True
                },
                pdf_trace
            )
            
            await asyncio.sleep(0.3)
            
            await local_monitor.update_agent_result(
                text_extractor,
                {
                    "extracted_text_length": 45678,
                    "confidence_score": 0.95,
                    "ocr_pages": 2,
                    "cleanup_applied": True
                },
                0.3,
                "completed"
            )
            print("  âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
            
            # 1.3 í‘œ ì²˜ë¦¬ ì—ì´ì „íŠ¸
            table_processor = await local_monitor.trace_agent_execution(
                "table_processor",
                {
                    "table_detection_method": "camelot-py",
                    "table_count": 8
                },
                pdf_trace
            )
            
            await asyncio.sleep(0.25)
            
            await local_monitor.update_agent_result(
                table_processor,
                {
                    "structured_tables": 8,
                    "total_cells": 456,
                    "extraction_accuracy": 0.92,
                    "format": "pandas_dataframe"
                },
                0.25,
                "completed"
            )
            print("  âœ… í‘œ ì²˜ë¦¬ ì™„ë£Œ")
            
            # 1.4 ì„ë² ë”© ìƒì„± ì—ì´ì „íŠ¸
            embedding_agent = await local_monitor.trace_agent_execution(
                "embedding_generator",
                {
                    "model": "text-embedding-3-large",
                    "chunk_strategy": "content_aware",
                    "chunk_count": 89
                },
                pdf_trace
            )
            
            await asyncio.sleep(0.4)
            
            await local_monitor.update_agent_result(
                embedding_agent,
                {
                    "embeddings_created": 89,
                    "dimensions": 3072,
                    "batch_size": 20,
                    "total_tokens": 17800
                },
                0.4,
                "completed"
            )
            print("  âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        
        print("âœ… PDF ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
        
        # 2. ê²€ìƒ‰ ì¿¼ë¦¬ ì›Œí¬í”Œë¡œìš°
        print("\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜...")
        
        async with local_monitor.trace_workflow(
            "search_query_pipeline",
            {
                "query": "ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "user_id": "user_123",
                "session_id": "session_456"
            }
        ) as search_trace:
            print("âœ… ê²€ìƒ‰ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            
            # 2.1 ì¿¼ë¦¬ ì „ì²˜ë¦¬
            query_processor = await local_monitor.trace_agent_execution(
                "query_processor",
                {
                    "original_query": "ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "preprocessing_steps": ["normalize", "tokenize", "intent_analysis"]
                },
                search_trace
            )
            
            await asyncio.sleep(0.1)
            
            await local_monitor.update_agent_result(
                query_processor,
                {
                    "processed_query": "ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´",
                    "intent": "policy_inquiry",
                    "keywords": ["ë³´í—˜ê¸ˆ", "ì§€ê¸‰", "ì¡°ê±´"],
                    "confidence": 0.89
                },
                0.1,
                "completed"
            )
            print("  âœ… ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì™„ë£Œ")
            
            # 2.2 ë²¡í„° ê²€ìƒ‰
            vector_search = await local_monitor.trace_agent_execution(
                "vector_search_engine",
                {
                    "query_embedding_dims": 3072,
                    "search_method": "cosine_similarity",
                    "top_k": 10
                },
                search_trace
            )
            
            await asyncio.sleep(0.15)
            
            await local_monitor.update_agent_result(
                vector_search,
                {
                    "matches_found": 7,
                    "top_score": 0.89,
                    "search_time_ms": 45,
                    "index_size": 89
                },
                0.15,
                "completed"
            )
            print("  âœ… ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ")
            
            # 2.3 ë‹µë³€ ìƒì„±
            answer_generator = await local_monitor.trace_agent_execution(
                "answer_generator",
                {
                    "model": "gpt-4o",
                    "context_chunks": 7,
                    "max_tokens": 500
                },
                search_trace
            )
            
            await asyncio.sleep(0.3)
            
            await local_monitor.update_agent_result(
                answer_generator,
                {
                    "answer_length": 245,
                    "sources_cited": 3,
                    "confidence_score": 0.92,
                    "generation_time": 0.3
                },
                0.3,
                "completed"
            )
            print("  âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
        
        print("âœ… ê²€ìƒ‰ ì¿¼ë¦¬ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
        
        # 3. ë©”íŠ¸ë¦­ ë¡œê¹… í…ŒìŠ¤íŠ¸
        print("\nğŸ“ˆ ì¢…í•© ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…...")
        
        comprehensive_metrics = {
            "session_id": "test_session_001",
            "total_workflows": 2,
            "total_agents": 7,
            "total_processing_time": 1.25,
            "memory_usage_mb": 512,
            "cpu_usage_percent": 45.2,
            "documents_processed": 1,
            "queries_processed": 1,
            "embeddings_created": 89,
            "search_accuracy": 0.89,
            "user_satisfaction": 0.95,
            "error_count": 0,
            "warning_count": 1,
            "timestamp": datetime.now().isoformat()
        }
        
        await local_monitor.log_metrics(comprehensive_metrics)
        print("âœ… ì¢…í•© ë©”íŠ¸ë¦­ ë¡œê¹… ì™„ë£Œ")
        
        # 4. í†µê³„ ì¡°íšŒ í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š ì›Œí¬í”Œë¡œìš° í†µê³„ ì¡°íšŒ...")
        
        stats = await local_monitor.get_workflow_stats()
        print(f"âœ… í†µê³„ ì¡°íšŒ ì™„ë£Œ:")
        print(f"  - ì´ ì‹¤í–‰ ìˆ˜: {stats.get('total_executions', 0)}")
        print(f"  - ì„±ê³µë¥ : {stats.get('success_rate', 0)}%")
        print(f"  - ë¡œê·¸ ë””ë ‰í† ë¦¬: {stats.get('log_directory', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë¡œì»¬ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_api_integration_local():
    """ë¡œì»¬ ëª¨ë‹ˆí„°ì™€ API í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸŒ ë¡œì»¬ ëª¨ë‹ˆí„° API í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        # í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì
        test_user = {"email": "test@ispl.com", "user_id": 1}
        
        # ì›Œí¬í”Œë¡œìš° API í…ŒìŠ¤íŠ¸
        from routers.workflow import get_workflow_summary
        
        print("ğŸ“Š ì›Œí¬í”Œë¡œìš° ìš”ì•½ API í…ŒìŠ¤íŠ¸...")
        summary = await get_workflow_summary(current_user=test_user)
        
        print(f"âœ… API ì‘ë‹µ ì„±ê³µ:")
        print(f"  - ëª¨ë‹ˆí„° íƒ€ì…: {summary.get('monitor_type', 'unknown')}")
        print(f"  - ëª¨ë‹ˆí„° í™œì„±í™”: {summary.get('monitor_enabled', False)}")
        print(f"  - ì´ ì›Œí¬í”Œë¡œìš°: {summary.get('total_workflows', 0)}")
        print(f"  - ì„±ê³µë¥ : {summary.get('success_rate', 0)}%")
        print(f"  - í‰ê·  ì‹¤í–‰ì‹œê°„: {summary.get('avg_execution_time', 0)}ms")
        
        # ëª¨ë‹ˆí„° í†µê³„ í™•ì¸
        monitor_stats = summary.get('monitor_stats', {})
        if monitor_stats:
            print(f"  - ë¡œì»¬ ëª¨ë‹ˆí„° í†µê³„: {monitor_stats}")
        
        return True
        
    except Exception as e:
        print(f"âŒ API í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


async def verify_log_files():
    """ìƒì„±ëœ ë¡œê·¸ íŒŒì¼ ê²€ì¦"""
    print("\n" + "=" * 60)
    print("ğŸ“ ë¡œê·¸ íŒŒì¼ ê²€ì¦")
    print("=" * 60)
    
    try:
        from pathlib import Path
        
        log_dir = Path("logs/workflow")
        
        if log_dir.exists():
            print(f"âœ… ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¡´ì¬: {log_dir}")
            
            # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸
            log_files = list(log_dir.glob("*.jsonl"))
            print(f"ğŸ“„ ìƒì„±ëœ ë¡œê·¸ íŒŒì¼ ìˆ˜: {len(log_files)}")
            
            for log_file in log_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                file_size = log_file.stat().st_size
                print(f"  ğŸ“„ {log_file.name} ({file_size} bytes)")
                
                # íŒŒì¼ ë‚´ìš© ì¼ë¶€ í™•ì¸
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        first_line = f.readline().strip()
                        if first_line:
                            import json
                            log_entry = json.loads(first_line)
                            print(f"     ğŸ” ì²« ë²ˆì§¸ ë¡œê·¸: {log_entry.get('event_type', 'unknown')}")
                except Exception as e:
                    print(f"     âš ï¸  íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            return True
        else:
            print(f"âš ï¸  ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {log_dir}")
            return False
            
    except Exception as e:
        print(f"âŒ ë¡œê·¸ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


async def main():
    """Self-hosted LangFuse ëŒ€ì•ˆ í…ŒìŠ¤íŠ¸ ë©”ì¸"""
    print("ğŸ  Self-hosted LangFuse ëŒ€ì•ˆ í…ŒìŠ¤íŠ¸")
    print("   (ë¡œì»¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ì „ í…ŒìŠ¤íŠ¸)")
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().isoformat()}")
    
    results = {}
    
    # 1. ë¡œì»¬ ëª¨ë‹ˆí„°ë§ ì™„ì „ í…ŒìŠ¤íŠ¸
    results['local_monitoring'] = await test_local_monitoring_complete()
    
    # 2. API í†µí•© í…ŒìŠ¤íŠ¸
    results['api_integration'] = await test_api_integration_local()
    
    # 3. ë¡œê·¸ íŒŒì¼ ê²€ì¦
    results['log_verification'] = await verify_log_files()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ Self-hosted LangFuse ëŒ€ì•ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("=" * 60)
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nğŸ¯ ì „ì²´ ê²°ê³¼: {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    print(f"â° ì™„ë£Œ ì‹œê°„: {datetime.now().isoformat()}")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("âœ… ë¡œì»¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì´ Self-hosted LangFuse ì™„ì „ ëŒ€ì²´")
        print("âœ… Task 6.1 ì™„ë£Œ: ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ì„±ê³µ")
    else:
        print("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    print("\nğŸ’¡ ë‹¬ì„±ëœ ê¸°ëŠ¥:")
    print("- ğŸ” ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° ì¶”ì ")
    print("- ğŸ“Š ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
    print("- ğŸ“ˆ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘")
    print("- ğŸ“ ì˜êµ¬ ë¡œê·¸ ì €ì¥")
    print("- ğŸŒ API í†µí•©")
    print("- ğŸ”„ ìë™ í´ë°± ì‹œìŠ¤í…œ")
    
    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)




