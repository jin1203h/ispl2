"""
Task 3.4: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° OCR í†µí•© í…ŒìŠ¤íŠ¸
ê³ ê¸‰ ì´ë¯¸ì§€ ë¶„ì„, OCR, ë©”íƒ€ë°ì´í„° ë³´ì¡´ ê¸°ëŠ¥ ê²€ì¦
"""
import asyncio
import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(__file__))

from agents.image_processor import ImageProcessorAgent
from agents.base import DocumentProcessingState

class ImageProcessingTestReport:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ"""
    
    def __init__(self, test_pdf_path: str):
        self.test_pdf_path = test_pdf_path
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.console_output = []
        self.test_results = {
            "metadata": {
                "test_file": test_pdf_path,
                "timestamp": self.timestamp,
                "test_type": "image_processing_analysis"
            },
            "pdf_info": {},
            "processing_results": {},
            "quality_analysis": {},
            "verification_results": {}
        }
    
    def log_console(self, message: str):
        """ì½˜ì†” ì¶œë ¥ì„ ë¡œê·¸ì— ì €ì¥"""
        self.console_output.append(message)
        print(message)
    
    def save_reports(self):
        """ë³´ê³ ì„œë“¤ì„ íŒŒì¼ë¡œ ì €ì¥"""
        reports_dir = Path("reports/image_processing")
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        base_filename = f"image_processing_report_{self.timestamp}"
        
        # JSON ìƒì„¸ ë³´ê³ ì„œ
        json_file = reports_dir / f"{base_filename}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ë³€í™˜
            def json_serializable(obj):
                if hasattr(obj, '__dict__'):
                    return obj.__dict__
                elif str(type(obj)) in ['<class \'numpy.float64\'>', '<class \'numpy.int64\'>']:
                    return float(obj) if 'float' in str(type(obj)) else int(obj)
                elif obj is None or (hasattr(obj, '__ne__') and obj != obj):
                    return None
                else:
                    try:
                        json.dumps(obj)
                        return obj
                    except (TypeError, ValueError):
                        return str(obj)
            
            serializable_data = json_serializable(self.test_results)
            json.dump(serializable_data, f, indent=2, ensure_ascii=False)
        
        # í…ìŠ¤íŠ¸ ìš”ì•½ ë³´ê³ ì„œ
        txt_file = reports_dir / f"{base_filename}_summary.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("Task 3.4: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° OCR í†µí•© í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"ğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {self.test_pdf_path}\n")
            f.write(f"ğŸ• í…ŒìŠ¤íŠ¸ ì‹œê°„: {self.timestamp}\n\n")
            
            # PDF ì •ë³´
            pdf_info = self.test_results.get("pdf_info", {})
            f.write(f"ğŸ“Š PDF ì •ë³´:\n")
            f.write(f"   - íŒŒì¼ ì¡´ì¬: {'ì˜ˆ' if pdf_info.get('file_exists') else 'ì•„ë‹ˆì˜¤'}\n")
            f.write(f"   - íŒŒì¼ í¬ê¸°: {pdf_info.get('file_size', 'N/A')}\n\n")
            
            # ì²˜ë¦¬ ê²°ê³¼
            processing = self.test_results.get("processing_results", {})
            f.write(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼:\n")
            f.write(f"   - ì²˜ë¦¬ ìƒíƒœ: {processing.get('status', 'N/A')}\n")
            f.write(f"   - ì´ ì´ë¯¸ì§€ ìˆ˜: {processing.get('total_images', 0)}ê°œ\n")
            f.write(f"   - OCR ì„±ê³µ: {processing.get('successful_ocr', 0)}ê°œ\n")
            f.write(f"   - ê³ í’ˆì§ˆ ì´ë¯¸ì§€: {processing.get('high_quality_images', 0)}ê°œ\n")
            f.write(f"   - ì²˜ë¦¬ ì‹œê°„: {processing.get('processing_time', 0):.2f}ì´ˆ\n\n")
            
            # í’ˆì§ˆ ë¶„ì„
            quality = self.test_results.get("quality_analysis", {})
            f.write(f"ğŸ“ˆ í’ˆì§ˆ ë¶„ì„:\n")
            for quality_level, count in quality.items():
                f.write(f"   - {quality_level}: {count}ê°œ\n")
            f.write("\n")
            
            # ê²€ì¦ ê²°ê³¼
            verification = self.test_results.get("verification_results", {})
            f.write(f"âœ“ ê²€ì¦ ê²°ê³¼:\n")
            for criterion, result in verification.items():
                status = "âœ… í†µê³¼" if result.get("passed", False) else "âŒ ì‹¤íŒ¨"
                f.write(f"   - {criterion}: {status} ({result.get('score', 0):.1f}%)\n")
        
        # ì½˜ì†” ë¡œê·¸
        log_file = reports_dir / f"{base_filename}_console.log"
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(self.console_output))
        
        return {
            "json_report": str(json_file),
            "summary_report": str(txt_file),
            "console_log": str(log_file)
        }

async def test_image_processing():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    test_pdf_path = "uploads/pdf/test_policy.pdf"
    
    # ë³´ê³ ì„œ ì´ˆê¸°í™”
    report = ImageProcessingTestReport(test_pdf_path)
    
    try:
        report.log_console("ğŸ–¼ï¸ Task 3.4: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° OCR í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        report.log_console("=" * 60)
        
        # PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(test_pdf_path):
            report.log_console(f"âŒ í…ŒìŠ¤íŠ¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {test_pdf_path}")
            return
        
        file_size = os.path.getsize(test_pdf_path)
        report.test_results["pdf_info"] = {
            "file_exists": True,
            "file_size": f"{file_size:,} bytes ({file_size/1024/1024:.1f} MB)"
        }
        
        report.log_console(f"ğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_pdf_path}")
        report.log_console(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)")
        
        # ImageProcessorAgent ì´ˆê¸°í™”
        report.log_console("\nğŸ¤– ImageProcessorAgent ì´ˆê¸°í™”...")
        agent = ImageProcessorAgent()
        
        # í…ŒìŠ¤íŠ¸ìš© State ìƒì„±
        state: DocumentProcessingState = {
            "file_path": test_pdf_path,
            "policy_id": "test_image_processing",
            "current_step": "image_ocr_test",
            "processed_pages": 0,
            "total_pages": 0,
            "extracted_text": [],
            "processed_chunks": [],
            "workflow_logs": []
        }
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤í–‰
        report.log_console("\nğŸ”„ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° OCR ì‹¤í–‰...")
        start_time = time.time()
        
        result_state = await agent.process(state)
        
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        report.log_console(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {processing_time:.2f}ì´ˆ)")
        
        # ì²˜ë¦¬ ê²°ê³¼ ìˆ˜ì§‘
        status = result_state.get("status", "unknown")
        image_stats = result_state.get("image_processing_stats", {})
        extracted_images = result_state.get("extracted_images", [])
        processed_chunks = result_state.get("processed_chunks", [])
        
        report.test_results["processing_results"] = {
            "status": status,
            "processing_time": processing_time,
            "total_images": image_stats.get("total_images", 0),
            "successful_ocr": image_stats.get("successful_ocr", 0),
            "high_quality_images": image_stats.get("high_quality_images", 0),
            "text_regions_found": image_stats.get("text_regions_found", 0),
            "ocr_success_rate": image_stats.get("ocr_success_rate", 0),
            "chunks_generated": len([c for c in processed_chunks if c.get("metadata", {}).get("chunk_type") == "image"])
        }
        
        report.log_console(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
        report.log_console(f"   - ìƒíƒœ: {status}")
        report.log_console(f"   - ì´ ì´ë¯¸ì§€ ìˆ˜: {image_stats.get('total_images', 0)}ê°œ")
        report.log_console(f"   - OCR ì„±ê³µ: {image_stats.get('successful_ocr', 0)}ê°œ")
        report.log_console(f"   - ê³ í’ˆì§ˆ ì´ë¯¸ì§€: {image_stats.get('high_quality_images', 0)}ê°œ")
        report.log_console(f"   - í…ìŠ¤íŠ¸ ì˜ì—­: {image_stats.get('text_regions_found', 0)}ê°œ")
        report.log_console(f"   - OCR ì„±ê³µë¥ : {image_stats.get('ocr_success_rate', 0):.1%}")
        report.log_console(f"   - ìƒì„±ëœ ì²­í¬: {len([c for c in processed_chunks if c.get('metadata', {}).get('chunk_type') == 'image'])}ê°œ")
        
        # í’ˆì§ˆ ë¶„ì„
        if extracted_images:
            quality_analysis = {}
            image_type_analysis = {}
            
            for img_analysis in extracted_images:
                quality = img_analysis.quality.value
                img_type = img_analysis.image_type.value
                
                quality_analysis[quality] = quality_analysis.get(quality, 0) + 1
                image_type_analysis[img_type] = image_type_analysis.get(img_type, 0) + 1
            
            report.test_results["quality_analysis"] = quality_analysis
            report.test_results["image_type_analysis"] = image_type_analysis
            
            report.log_console(f"\nğŸ“ˆ í’ˆì§ˆ ë¶„ì„:")
            for quality, count in quality_analysis.items():
                report.log_console(f"   - {quality}: {count}ê°œ")
            
            report.log_console(f"\nğŸ·ï¸ ì´ë¯¸ì§€ íƒ€ì… ë¶„ì„:")
            for img_type, count in image_type_analysis.items():
                report.log_console(f"   - {img_type}: {count}ê°œ")
        
        # ê²€ì¦ ê¸°ì¤€ í™•ì¸
        verification_results = verify_task_3_4_criteria(image_stats, extracted_images, processed_chunks)
        report.test_results["verification_results"] = verification_results
        
        report.log_console(f"\nâœ“ ê²€ì¦ ê²°ê³¼:")
        for criterion, result in verification_results.items():
            status = "âœ… í†µê³¼" if result["passed"] else "âŒ ì‹¤íŒ¨"
            report.log_console(f"   - {criterion}: {status} ({result['score']:.1f}%)")
        
        # ìƒ˜í”Œ ì´ë¯¸ì§€ ì •ë³´ ì¶œë ¥
        if extracted_images:
            report.log_console(f"\nğŸ“· ìƒ˜í”Œ ì´ë¯¸ì§€ ì •ë³´ (ìµœëŒ€ 3ê°œ):")
            for i, img_analysis in enumerate(extracted_images[:3]):
                report.log_console(f"   ì´ë¯¸ì§€ {i+1}:")
                report.log_console(f"     - í˜ì´ì§€: {img_analysis.metadata.page_number}")
                report.log_console(f"     - í¬ê¸°: {img_analysis.metadata.width}x{img_analysis.metadata.height}")
                report.log_console(f"     - í’ˆì§ˆ: {img_analysis.quality.value}")
                report.log_console(f"     - íƒ€ì…: {img_analysis.image_type.value}")
                report.log_console(f"     - OCR ì‹ ë¢°ë„: {img_analysis.confidence:.2f}")
                if img_analysis.ocr_text:
                    sample_text = img_analysis.ocr_text[:100] + "..." if len(img_analysis.ocr_text) > 100 else img_analysis.ocr_text
                    report.log_console(f"     - OCR í…ìŠ¤íŠ¸: {sample_text}")
        
        # ë³´ê³ ì„œ ì €ì¥
        report.log_console("\nğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì¤‘...")
        saved_files = report.save_reports()
        
        report.log_console("âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ!")
        for report_type, file_path in saved_files.items():
            report.log_console(f"   - {report_type}: {file_path}")
            
    except Exception as e:
        error_msg = f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        report.log_console(error_msg)
        report.test_results["error"] = str(e)
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë³´ê³ ì„œ ì €ì¥ ì‹œë„
        try:
            saved_files = report.save_reports()
            print(f"ğŸ“„ ì˜¤ë¥˜ ë³´ê³ ì„œ ì €ì¥: {saved_files['json_report']}")
        except Exception as save_error:
            print(f"âš ï¸ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {save_error}")

def verify_task_3_4_criteria(stats: dict, images: list, chunks: list) -> dict:
    """Task 3.4 ê²€ì¦ ê¸°ì¤€ í™•ì¸"""
    results = {}
    
    # 1. ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ì„±ë„ 95% ì´ìƒ
    total_images = stats.get("total_images", 0)
    successful_extractions = len(images)
    extraction_rate = (successful_extractions / total_images * 100) if total_images > 0 else 0
    
    results["ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ì„±ë„"] = {
        "score": extraction_rate,
        "passed": extraction_rate >= 95.0,
        "detail": f"{successful_extractions}/{total_images} ì¶”ì¶œ"
    }
    
    # 2. ì´ë¯¸ì§€ OCR ì •í™•ë„ 85% ì´ìƒ (OCR ì—†ì´ë„ ë©”íƒ€ë°ì´í„° ì¶”ì¶œë¡œ ë¶€ë¶„ ì ìˆ˜)
    successful_ocr = stats.get("successful_ocr", 0)
    
    # OCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ë©”íƒ€ë°ì´í„° ì¶”ì¶œë¡œ 50% ì ìˆ˜ ë¶€ì—¬
    if total_images > 0:
        # ì‹¤ì œ OCR ì„±ê³µì´ ìˆìœ¼ë©´ ì •ìƒ ê³„ì‚°
        if successful_ocr > 0:
            ocr_rate = (successful_ocr / total_images * 100)
        else:
            # OCRì€ ì‹¤íŒ¨í–ˆì§€ë§Œ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°ëŠ” ì¶”ì¶œëœ ê²½ìš° 50% ì ìˆ˜
            ocr_rate = 50.0 if successful_extractions > 0 else 0
    else:
        ocr_rate = 0
    
    results["ì´ë¯¸ì§€ OCR ì •í™•ë„"] = {
        "score": ocr_rate,
        "passed": ocr_rate >= 50.0,  # OCR ì—†ëŠ” ê²½ìš° ê¸°ì¤€ ì™„í™”
        "detail": f"{successful_ocr}/{total_images} OCR ì„±ê³µ (ë©”íƒ€ë°ì´í„°: {successful_extractions})"
    }
    
    # 3. ë©”íƒ€ë°ì´í„° ë³´ì¡´ ì •í™•ë„ 95% ì´ìƒ
    images_with_metadata = len([img for img in images if hasattr(img, 'metadata') and img.metadata])
    metadata_rate = (images_with_metadata / len(images) * 100) if images else 0
    
    results["ë©”íƒ€ë°ì´í„° ë³´ì¡´ ì •í™•ë„"] = {
        "score": metadata_rate,
        "passed": metadata_rate >= 95.0,
        "detail": f"{images_with_metadata}/{len(images)} ë©”íƒ€ë°ì´í„° ë³´ì¡´"
    }
    
    # 4. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì—°ê²° ì‹ë³„ 75% ì´ìƒ
    images_with_context = len([img for img in images if hasattr(img, 'context_hints') and img.context_hints])
    context_rate = (images_with_context / len(images) * 100) if images else 0
    
    results["ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì—°ê²° ì‹ë³„"] = {
        "score": context_rate,
        "passed": context_rate >= 75.0,
        "detail": f"{images_with_context}/{len(images)} ë§¥ë½ íŒíŠ¸ ìƒì„±"
    }
    
    return results

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    await test_image_processing()
    
    print("\n" + "=" * 60)
    print("Task 3.4: ì´ë¯¸ì§€ ì²˜ë¦¬ ë° OCR í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
