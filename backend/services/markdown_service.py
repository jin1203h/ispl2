"""
Markdown ë³€í™˜ ì „ìš© ì„œë¹„ìŠ¤
PDFì—ì„œ ì¶”ì¶œëœ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""
import re
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path
import yaml
import pandas as pd

from utils.structure_analyzer import (
    DocumentStructureAnalyzer, 
    StructureElement, 
    ContentType, 
    StructureLevel
)

logger = logging.getLogger(__name__)

class MarkdownConverter:
    """Markdown ë³€í™˜ê¸°"""
    
    def __init__(self):
        self.structure_analyzer = DocumentStructureAnalyzer()
        
        # Markdown í—¤ë” ë ˆë²¨ ë§¤í•‘
        self.header_level_mapping = {
            StructureLevel.CHAPTER.value: 1,
            StructureLevel.SECTION.value: 2,
            StructureLevel.SUBSECTION.value: 3,
            StructureLevel.PARAGRAPH.value: 4
        }
        
        # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬
        self.image_dir = "images"
        
        # ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
        self.supported_image_formats = {'.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp'}

    def convert_to_markdown(self, 
                          processed_chunks: List[Dict[str, Any]], 
                          document_metadata: Optional[Dict[str, Any]] = None,
                          include_toc: bool = True,
                          include_metadata: bool = True) -> str:
        """PDF ì²˜ë¦¬ ê²°ê³¼ë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
        
        logger.info("Markdown ë³€í™˜ ì‹œì‘")
        
        # 1. ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
        structure = self.structure_analyzer.analyze_document_structure(processed_chunks)
        
        # 2. Markdown ë¬¸ì„œ ìƒì„±
        markdown_content = []
        
        # 3. ë©”íƒ€ë°ì´í„° (YAML í”„ë¡ íŠ¸ë§¤í„°) ì¶”ê°€
        if include_metadata:
            frontmatter = self._generate_frontmatter(document_metadata, structure)
            markdown_content.append(frontmatter)
        
        # 4. ëª©ì°¨ ìƒì„±
        if include_toc:
            toc = self._generate_table_of_contents(structure)
            if toc:
                markdown_content.append(toc)
        
        # 5. ë³¸ë¬¸ ë³€í™˜
        body = self._convert_structure_to_markdown(structure)
        markdown_content.append(body)
        
        # 6. ê°ì£¼ ë° ì°¸ì¡° ì¶”ê°€
        footnotes = self._extract_and_format_footnotes(structure)
        if footnotes:
            markdown_content.append(footnotes)
        
        final_markdown = "\n\n".join(markdown_content)
        
        logger.info(f"Markdown ë³€í™˜ ì™„ë£Œ: {len(final_markdown)} ë¬¸ì")
        return final_markdown

    def _generate_frontmatter(self, 
                            document_metadata: Optional[Dict[str, Any]], 
                            structure: List[StructureElement]) -> str:
        """YAML í”„ë¡ íŠ¸ë§¤í„° ìƒì„±"""
        
        # ë¬¸ì„œ í†µê³„
        stats = self.structure_analyzer.analyze_document_statistics(structure)
        
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
        frontmatter_data = {
            "title": document_metadata.get("title", "Untitled Document") if document_metadata else "Untitled Document",
            "generated_at": datetime.now().isoformat(),
            "generator": "ISPL PDF Processor",
            "source_format": "PDF",
            "document_statistics": {
                "total_pages": stats.get("total_pages", 0),
                "total_elements": stats.get("total_elements", 0),
                "content_types": stats.get("content_types", {}),
                "average_text_length": round(stats.get("average_text_length", 0), 2)
            }
        }
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë³‘í•©
        if document_metadata:
            frontmatter_data.update({
                "author": document_metadata.get("author"),
                "subject": document_metadata.get("subject"),
                "keywords": document_metadata.get("keywords"),
                "creation_date": document_metadata.get("creation_date"),
                "modification_date": document_metadata.get("modification_date"),
                "file_size": document_metadata.get("file_size"),
                "language": document_metadata.get("language", "ko")
            })
        
        # None ê°’ ì œê±°
        frontmatter_data = {k: v for k, v in frontmatter_data.items() if v is not None}
        
        yaml_content = yaml.dump(frontmatter_data, default_flow_style=False, allow_unicode=True)
        return f"---\n{yaml_content}---"

    def _generate_table_of_contents(self, structure: List[StructureElement]) -> str:
        """ëª©ì°¨ ìƒì„±"""
        toc_items = self.structure_analyzer.get_table_of_contents(structure)
        
        if not toc_items:
            return ""
        
        toc_lines = ["## ëª©ì°¨", ""]
        
        for item in toc_items:
            # ë“¤ì—¬ì“°ê¸° ê³„ì‚°
            indent = "  " * item["depth"]
            
            # ì œëª©ì—ì„œ íŠ¹ìˆ˜ ë¬¸ì ì œê±°í•˜ì—¬ ì•µì»¤ ìƒì„±
            anchor = self._create_anchor(item["title"])
            
            # ëª©ì°¨ í•­ëª© ìƒì„±
            toc_line = f"{indent}- [{item['title']}](#{anchor}) (í˜ì´ì§€ {item['page']})"
            toc_lines.append(toc_line)
        
        return "\n".join(toc_lines)

    def _create_anchor(self, title: str) -> str:
        """ì œëª©ì—ì„œ Markdown ì•µì»¤ ìƒì„±"""
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ì†Œë¬¸ìë¡œ ë³€í™˜
        anchor = re.sub(r'[^\w\sê°€-í£]', '', title)
        anchor = re.sub(r'\s+', '-', anchor.strip())
        anchor = anchor.lower()
        return anchor

    def _convert_structure_to_markdown(self, structure: List[StructureElement]) -> str:
        """êµ¬ì¡°í™”ëœ ìš”ì†Œë“¤ì„ Markdownìœ¼ë¡œ ë³€í™˜"""
        markdown_lines = []
        
        for element in structure:
            converted = self._convert_element_to_markdown(element)
            if converted:
                markdown_lines.append(converted)
        
        return "\n\n".join(markdown_lines)

    def _convert_element_to_markdown(self, element: StructureElement) -> str:
        """ê°œë³„ ìš”ì†Œë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
        
        if element.content_type == ContentType.TITLE:
            markdown = f"# {element.text}"
            
        elif element.content_type == ContentType.HEADER:
            level = self.header_level_mapping.get(element.level, 2)
            markdown = f"{'#' * level} {element.text}"
            
        elif element.content_type == ContentType.SUBHEADER:
            level = self.header_level_mapping.get(element.level, 3)
            markdown = f"{'#' * level} {element.text}"
            
        elif element.content_type == ContentType.PARAGRAPH:
            markdown = element.text
            
        elif element.content_type == ContentType.LIST_ITEM:
            # ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ í˜•ì‹ ì •ë¦¬
            clean_text = re.sub(r'^\s*[-*â€¢]\s+', '', element.text)
            clean_text = re.sub(r'^\s*\d+\)\s+', '', clean_text)
            clean_text = re.sub(r'^\s*[ê°€-í£a-zA-Z]\)\s+', '', clean_text)
            markdown = f"- {clean_text}"
            
        elif element.content_type == ContentType.TABLE:
            markdown = self._convert_table_to_markdown(element)
            
        elif element.content_type == ContentType.IMAGE:
            markdown = self._convert_image_to_markdown(element)
            
        elif element.content_type == ContentType.QUOTE:
            # ì¸ìš©ë¬¸ ì²˜ë¦¬
            quote_text = element.text.strip('"\'ã€Œã€ã€ã€""''')
            markdown = f"> {quote_text}"
            
        elif element.content_type == ContentType.CODE:
            markdown = f"```\n{element.text}\n```"
            
        elif element.content_type == ContentType.FOOTNOTE:
            # ê°ì£¼ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
            return ""
            
        else:
            markdown = element.text
        
        # ìì‹ ìš”ì†Œë“¤ ì²˜ë¦¬
        if element.children:
            child_content = []
            for child in element.children:
                child_markdown = self._convert_element_to_markdown(child)
                if child_markdown:
                    child_content.append(child_markdown)
            
            if child_content:
                markdown += "\n\n" + "\n\n".join(child_content)
        
        return markdown

    def _convert_table_to_markdown(self, element: StructureElement) -> str:
        """í‘œ ìš”ì†Œë¥¼ Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ í‘œ ë°ì´í„° ì¶”ì¶œ
        table_data = element.metadata.get("table_data")
        
        if not table_data:
            return f"*[í‘œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: í˜ì´ì§€ {element.page_number}]*"
        
        try:
            # pandas DataFrameì¸ ê²½ìš°
            if hasattr(table_data, 'to_markdown'):
                return table_data.to_markdown(index=False)
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš°
            elif isinstance(table_data, list) and table_data:
                return self._list_to_markdown_table(table_data)
            
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
            elif isinstance(table_data, dict):
                # ë”•ì…”ë„ˆë¦¬ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ ì‹œë„
                try:
                    df = pd.DataFrame(table_data)
                    return df.to_markdown(index=False)
                except:
                    # ë³€í™˜ ì‹¤íŒ¨ ì‹œ í‚¤-ê°’ ìŒìœ¼ë¡œ í‘œì‹œ
                    rows = [["í•­ëª©", "ê°’"]]
                    rows.extend([[str(k), str(v)] for k, v in table_data.items()])
                    return self._list_to_markdown_table(rows)
            
            else:
                return f"*[ì§€ì›ë˜ì§€ ì•ŠëŠ” í‘œ í˜•ì‹: í˜ì´ì§€ {element.page_number}]*"
                
        except Exception as e:
            logger.warning(f"í‘œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return f"*[í‘œ ë³€í™˜ ì˜¤ë¥˜: í˜ì´ì§€ {element.page_number}]*"

    def _list_to_markdown_table(self, table_data: List[List[str]]) -> str:
        """2ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¥¼ Markdown í‘œë¡œ ë³€í™˜"""
        if not table_data or not table_data[0]:
            return "*[ë¹ˆ í‘œ]*"
        
        # í—¤ë” í–‰
        header = table_data[0]
        markdown_lines = []
        
        # í—¤ë” ë¼ì¸
        header_line = "| " + " | ".join(str(cell) for cell in header) + " |"
        markdown_lines.append(header_line)
        
        # êµ¬ë¶„ì ë¼ì¸
        separator_line = "| " + " | ".join("---" for _ in header) + " |"
        markdown_lines.append(separator_line)
        
        # ë°ì´í„° í–‰ë“¤
        for row in table_data[1:]:
            # í–‰ì˜ ì—´ ìˆ˜ë¥¼ í—¤ë”ì™€ ë§ì¶¤
            padded_row = (list(row) + [""] * len(header))[:len(header)]
            row_line = "| " + " | ".join(str(cell) for cell in padded_row) + " |"
            markdown_lines.append(row_line)
        
        return "\n".join(markdown_lines)

    def _convert_image_to_markdown(self, element: StructureElement) -> str:
        """ì´ë¯¸ì§€ ìš”ì†Œë¥¼ Markdown ì´ë¯¸ì§€ ë§í¬ë¡œ ë³€í™˜"""
        
        # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        image_metadata = element.metadata.get("image_analysis", {})
        page_number = element.page_number
        image_index = element.metadata.get("image_index", 0)
        
        # ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±
        image_filename = f"page_{page_number}_image_{image_index}.png"
        image_path = f"{self.image_dir}/{image_filename}"
        
        # ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
        alt_text = self._generate_image_alt_text(element, image_metadata)
        
        # Markdown ì´ë¯¸ì§€ ë§í¬ ìƒì„±
        markdown = f"![{alt_text}]({image_path})"
        
        # ì´ë¯¸ì§€ ìº¡ì…˜ ì¶”ê°€ (OCR í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°)
        ocr_text = element.text.strip()
        if ocr_text and not ocr_text.startswith("["):
            caption = f"\n\n*{ocr_text}*"
            markdown += caption
        
        # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì •ë³´ ì¶”ê°€ (ë””ë²„ê·¸ìš©)
        if image_metadata:
            quality = image_metadata.get("quality", "ì•Œ ìˆ˜ ì—†ìŒ")
            image_type = image_metadata.get("image_type", "ì•Œ ìˆ˜ ì—†ìŒ")
            confidence = image_metadata.get("confidence", 0)
            
            metadata_comment = f"\n<!-- ì´ë¯¸ì§€ ì •ë³´: í’ˆì§ˆ={quality}, íƒ€ì…={image_type}, OCR ì‹ ë¢°ë„={confidence:.2f} -->"
            markdown += metadata_comment
        
        return markdown

    def _generate_image_alt_text(self, element: StructureElement, image_metadata: Dict[str, Any]) -> str:
        """ì´ë¯¸ì§€ ëŒ€ì²´ í…ìŠ¤íŠ¸ ìƒì„±"""
        
        page_number = element.page_number
        image_type = image_metadata.get("image_type", "ì´ë¯¸ì§€")
        
        # OCR í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê°„ë‹¨í•œ ì„¤ëª… ìƒì„±
        ocr_text = element.text.strip()
        if ocr_text and not ocr_text.startswith("["):
            # ì²« ëª‡ ë‹¨ì–´ë§Œ ì‚¬ìš©
            words = ocr_text.split()[:5]
            preview = " ".join(words)
            if len(words) == 5:
                preview += "..."
            return f"í˜ì´ì§€ {page_number} {image_type}: {preview}"
        
        return f"í˜ì´ì§€ {page_number} {image_type}"

    def _extract_and_format_footnotes(self, structure: List[StructureElement]) -> str:
        """ê°ì£¼ ì¶”ì¶œ ë° í˜•ì‹í™”"""
        footnotes = []
        
        def collect_footnotes(elements: List[StructureElement]):
            for element in elements:
                if element.content_type == ContentType.FOOTNOTE:
                    footnotes.append(element)
                if element.children:
                    collect_footnotes(element.children)
        
        collect_footnotes(structure)
        
        if not footnotes:
            return ""
        
        footnote_lines = ["## ê°ì£¼", ""]
        
        for i, footnote in enumerate(footnotes, 1):
            footnote_text = footnote.text.strip()
            # ê¸°ì¡´ ê°ì£¼ ë²ˆí˜¸ ì œê±°
            footnote_text = re.sub(r'^\*+\s*', '', footnote_text)
            footnote_text = re.sub(r'^\d+\)\s*', '', footnote_text)
            footnote_text = re.sub(r'^ì£¼\s*\d+\)\s*', '', footnote_text)
            
            footnote_lines.append(f"[^{i}]: {footnote_text}")
        
        return "\n".join(footnote_lines)

    def save_markdown_to_file(self, 
                            markdown_content: str, 
                            output_path: str,
                            extract_images: bool = True,
                            processed_chunks: Optional[List[Dict[str, Any]]] = None) -> Dict[str, Any]:
        """Markdown ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥"""
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Markdown íŒŒì¼ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        result = {
            "markdown_file": str(output_path),
            "file_size": output_path.stat().st_size,
            "extracted_images": []
        }
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì¶”ì¶œ ë° ì €ì¥
        if extract_images and processed_chunks:
            image_dir = output_path.parent / self.image_dir
            image_dir.mkdir(exist_ok=True)
            
            extracted_images = self._extract_and_save_images(processed_chunks, image_dir)
            result["extracted_images"] = extracted_images
        
        logger.info(f"Markdown íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        return result

    def _extract_and_save_images(self, 
                                processed_chunks: List[Dict[str, Any]], 
                                image_dir: Path) -> List[Dict[str, Any]]:
        """ì²˜ë¦¬ëœ ì²­í¬ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥"""
        extracted_images = []
        
        for chunk in processed_chunks:
            metadata = chunk.get("metadata", {})
            chunk_type = metadata.get("chunk_type", "")
            
            if chunk_type == "image":
                try:
                    page_number = metadata.get("page_number", 1)
                    image_index = metadata.get("image_index", 0)
                    
                    # ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
                    image_data = metadata.get("image_data")
                    
                    # ë”ë¯¸ ë°ì´í„°ì¸ ê²½ìš° ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±
                    if not image_data or image_data == b"dummy_image_data":
                        image_data = self._create_placeholder_image(chunk.get("text", "ìƒ˜í”Œ ì´ë¯¸ì§€"))
                    
                    if not image_data:
                        logger.warning(f"í˜ì´ì§€ {page_number} ì´ë¯¸ì§€ {image_index}: ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ")
                        continue
                    
                    # íŒŒì¼ëª… ìƒì„±
                    image_filename = f"page_{page_number}_image_{image_index}.png"
                    image_path = image_dir / image_filename
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    with open(image_path, 'wb') as f:
                        f.write(image_data)
                    
                    extracted_images.append({
                        "filename": image_filename,
                        "path": str(image_path),
                        "page_number": page_number,
                        "image_index": image_index,
                        "size_bytes": len(image_data),
                        "is_placeholder": image_data == self._create_placeholder_image(chunk.get("text", "ìƒ˜í”Œ ì´ë¯¸ì§€"))
                    })
                    
                    logger.info(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {image_filename} ({len(image_data)} bytes)")
                    
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì´ë¯¸ì§€ {len(extracted_images)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        return extracted_images

    def _create_placeholder_image(self, text: str = "ìƒ˜í”Œ ì´ë¯¸ì§€") -> bytes:
        """í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ìƒì„±"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            import io
            
            # ì´ë¯¸ì§€ í¬ê¸°
            width, height = 400, 200
            
            # ì´ë¯¸ì§€ ìƒì„±
            img = Image.new('RGB', (width, height), color='lightgray')
            draw = ImageDraw.Draw(img)
            
            # í…ìŠ¤íŠ¸ ì¶”ê°€
            try:
                # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                font = ImageFont.load_default()
            except:
                font = None
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚°
            text_lines = [
                "ğŸ“„ ISPL Insurance Policy",
                text[:30] + ("..." if len(text) > 30 else ""),
                "Sample Image Placeholder"
            ]
            
            y_offset = 50
            for line in text_lines:
                if font:
                    bbox = draw.textbbox((0, 0), line, font=font)
                    text_width = bbox[2] - bbox[0]
                    text_height = bbox[3] - bbox[1]
                else:
                    text_width, text_height = len(line) * 8, 12
                
                x = (width - text_width) // 2
                draw.text((x, y_offset), line, fill='black', font=font)
                y_offset += text_height + 10
            
            # í…Œë‘ë¦¬ ê·¸ë¦¬ê¸°
            draw.rectangle([5, 5, width-5, height-5], outline='gray', width=2)
            
            # PNG ë°”ì´íŠ¸ë¡œ ë³€í™˜
            img_buffer = io.BytesIO()
            img.save(img_buffer, format='PNG')
            return img_buffer.getvalue()
            
        except ImportError:
            logger.warning("PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            # ìµœì†Œí•œì˜ PNG í—¤ë” (ë¹ˆ ì´ë¯¸ì§€)
            return b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\tpHYs\x00\x00\x0b\x13\x00\x00\x0b\x13\x01\x00\x9a\x9c\x18\x00\x00\x00\x12IDATx\x9cc```\x04\x00\x00\x05\x00\x01\r\n-\xdb\x00\x00\x00\x00IEND\xaeB`\x82'
        except Exception as e:
            logger.error(f"í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return b""

    def generate_conversion_report(self, 
                                 structure: List[StructureElement],
                                 conversion_result: Dict[str, Any]) -> Dict[str, Any]:
        """ë³€í™˜ ë³´ê³ ì„œ ìƒì„±"""
        
        stats = self.structure_analyzer.analyze_document_statistics(structure)
        toc = self.structure_analyzer.get_table_of_contents(structure)
        
        report = {
            "conversion_timestamp": datetime.now().isoformat(),
            "document_statistics": stats,
            "table_of_contents": toc,
            "conversion_results": conversion_result,
            "quality_metrics": {
                "structure_preservation_rate": self._calculate_structure_preservation_rate(structure),
                "markdown_syntax_compliance": True,  # ê¸°ë³¸ì ìœ¼ë¡œ ì¤€ìˆ˜
                "readability_score": self._calculate_readability_score(structure),
                "metadata_completeness": self._calculate_metadata_completeness(structure)
            }
        }
        
        return report

    def _calculate_structure_preservation_rate(self, structure: List[StructureElement]) -> float:
        """êµ¬ì¡° ë³´ì¡´ìœ¨ ê³„ì‚°"""
        total_elements = 0
        preserved_elements = 0
        
        def count_preserved(elements: List[StructureElement]):
            nonlocal total_elements, preserved_elements
            
            for element in elements:
                total_elements += 1
                
                # êµ¬ì¡° ì •ë³´ê°€ ë³´ì¡´ëœ ìš”ì†Œ ì¹´ìš´íŠ¸
                if (element.content_type != ContentType.PARAGRAPH and 
                    element.level > 0 and 
                    element.text.strip()):
                    preserved_elements += 1
                elif element.content_type == ContentType.PARAGRAPH and element.text.strip():
                    preserved_elements += 1
                
                if element.children:
                    count_preserved(element.children)
        
        count_preserved(structure)
        
        return (preserved_elements / total_elements * 100) if total_elements > 0 else 0

    def _calculate_readability_score(self, structure: List[StructureElement]) -> str:
        """ê°€ë…ì„± ì ìˆ˜ ê³„ì‚°"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°€ë…ì„± í‰ê°€
        
        total_text_length = 0
        header_count = 0
        paragraph_count = 0
        
        def analyze_readability(elements: List[StructureElement]):
            nonlocal total_text_length, header_count, paragraph_count
            
            for element in elements:
                total_text_length += len(element.text)
                
                if element.content_type in [ContentType.TITLE, ContentType.HEADER, ContentType.SUBHEADER]:
                    header_count += 1
                elif element.content_type == ContentType.PARAGRAPH:
                    paragraph_count += 1
                
                if element.children:
                    analyze_readability(element.children)
        
        analyze_readability(structure)
        
        # ê°€ë…ì„± ì ìˆ˜ ê³„ì‚° (í—¤ë”ì™€ ë¬¸ë‹¨ì˜ ë¹„ìœ¨ ë“± ê³ ë ¤)
        if paragraph_count == 0:
            return "ë¶ˆëŸ‰"
        
        header_to_paragraph_ratio = header_count / paragraph_count
        avg_paragraph_length = total_text_length / paragraph_count if paragraph_count > 0 else 0
        
        if header_to_paragraph_ratio > 0.3 and 50 <= avg_paragraph_length <= 500:
            return "ìš°ìˆ˜"
        elif header_to_paragraph_ratio > 0.1 and 30 <= avg_paragraph_length <= 800:
            return "ì–‘í˜¸"
        else:
            return "ë³´í†µ"

    def _calculate_metadata_completeness(self, structure: List[StructureElement]) -> float:
        """ë©”íƒ€ë°ì´í„° ì™„ì„±ë„ ê³„ì‚°"""
        total_elements = 0
        elements_with_metadata = 0
        
        def count_metadata(elements: List[StructureElement]):
            nonlocal total_elements, elements_with_metadata
            
            for element in elements:
                total_elements += 1
                
                # ë©”íƒ€ë°ì´í„° í•­ëª© í™•ì¸
                has_position = element.position and any(element.position.values())
                has_page_number = element.page_number > 0
                has_content_type = element.content_type is not None
                has_metadata = bool(element.metadata)
                
                metadata_score = sum([has_position, has_page_number, has_content_type, has_metadata])
                if metadata_score >= 3:  # 4ê°œ ì¤‘ 3ê°œ ì´ìƒ
                    elements_with_metadata += 1
                
                if element.children:
                    count_metadata(element.children)
        
        count_metadata(structure)
        
        return (elements_with_metadata / total_elements * 100) if total_elements > 0 else 0
