"""
ì‹¤ì œ pgvector ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
HNSW ì¸ë±ìŠ¤ ìƒì„±, ë²¡í„° ì‚½ì…, ê²€ìƒ‰ ì„±ëŠ¥ ì‹¤ì œ ì¸¡ì •
"""
import asyncio
import time
import logging
from typing import List
import random

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_vector_operations():
    """ì‹¤ì œ ë²¡í„° ì—°ì‚° í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ì‹¤ì œ pgvector ë²¡í„° ì—°ì‚° í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        from services.database import get_async_session
        from sqlalchemy import text
        
        async with get_async_session() as db:
            # 1. ë²¡í„° ìƒì„± ë° ì‚½ì… í…ŒìŠ¤íŠ¸
            print("1. ë²¡í„° ìƒì„± ë° ì‚½ì… í…ŒìŠ¤íŠ¸...")
            
            # ê°„ë‹¨í•œ 3ì°¨ì› ë²¡í„°ë¡œ í…ŒìŠ¤íŠ¸ (ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´)
            test_vectors = [
                [1.0, 0.0, 0.0],
                [0.0, 1.0, 0.0], 
                [0.0, 0.0, 1.0],
                [0.5, 0.5, 0.5],
                [0.8, 0.1, 0.1]
            ]
            
            # í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ í…Œì´ë¸” ìƒì„±
            create_table_sql = """
                CREATE TEMP TABLE test_vectors (
                    id SERIAL PRIMARY KEY,
                    embedding vector(3),
                    description TEXT
                )
            """
            await db.execute(text(create_table_sql))
            
            # ë²¡í„° ì‚½ì…
            for i, vec in enumerate(test_vectors):
                # ë²¡í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                vec_str = "[" + ",".join(map(str, vec)) + "]"
                insert_sql = """
                    INSERT INTO test_vectors (embedding, description) 
                    VALUES (:embedding, :description)
                """
                await db.execute(text(insert_sql), {
                    "embedding": vec_str,
                    "description": f"í…ŒìŠ¤íŠ¸ ë²¡í„° {i+1}"
                })
            
            await db.commit()
            print(f"   âœ… {len(test_vectors)}ê°œ ë²¡í„° ì‚½ì… ì™„ë£Œ")
            
            # 2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            print("2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
            
            query_vector = [1.0, 0.0, 0.0]  # ì²« ë²ˆì§¸ ë²¡í„°ì™€ ë™ì¼
            query_vector_str = "[" + ",".join(map(str, query_vector)) + "]"
            
            similarity_sql = """
                SELECT 
                    id,
                    description,
                    embedding,
                    1 - (embedding <=> :query_vector) as similarity
                FROM test_vectors 
                ORDER BY embedding <=> :query_vector
                LIMIT 3
            """
            
            start_time = time.time()
            result = await db.execute(text(similarity_sql), {"query_vector": query_vector_str})
            search_time = (time.time() - start_time) * 1000  # ms
            
            rows = result.fetchall()
            
            print(f"   ì¿¼ë¦¬ ë²¡í„°: {query_vector}")
            print(f"   ê²€ìƒ‰ ì‹œê°„: {search_time:.2f}ms")
            print("   ê²€ìƒ‰ ê²°ê³¼:")
            
            for row in rows:
                print(f"     ID: {row.id}, ì„¤ëª…: {row.description}, ìœ ì‚¬ë„: {row.similarity:.4f}")
            
            return True
            
    except Exception as e:
        print(f"âŒ ë²¡í„° ì—°ì‚° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

async def test_index_creation():
    """ì‹¤ì œ HNSW ì¸ë±ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ì‹¤ì œ HNSW ì¸ë±ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        from services.database import get_async_session
        from sqlalchemy import text
        
        async with get_async_session() as db:
            # 1. ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸
            print("1. ê¸°ì¡´ ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸...")
            
            index_check_sql = """
                SELECT indexname, indexdef 
                FROM pg_indexes 
                WHERE tablename = 'embeddings_text_embedding_3'
                AND indexname LIKE '%hnsw%'
            """
            
            result = await db.execute(text(index_check_sql))
            existing_indexes = result.fetchall()
            
            if existing_indexes:
                print("   ê¸°ì¡´ HNSW ì¸ë±ìŠ¤:")
                for idx in existing_indexes:
                    print(f"     - {idx.indexname}")
            else:
                print("   ê¸°ì¡´ HNSW ì¸ë±ìŠ¤ ì—†ìŒ")
            
            # 2. ì‘ì€ í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤ ìƒì„±
            print("2. í…ŒìŠ¤íŠ¸ìš© HNSW ì¸ë±ìŠ¤ ìƒì„±...")
            
            # í…ŒìŠ¤íŠ¸ìš© ì‘ì€ í…Œì´ë¸” ìƒì„± (ë¹ ë¥¸ ì¸ë±ìŠ¤ ìƒì„±ì„ ìœ„í•´)
            create_test_table_sql = """
                CREATE TEMP TABLE test_hnsw (
                    id SERIAL PRIMARY KEY,
                    embedding vector(128)  -- ì‘ì€ ì°¨ì›ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
                )
            """
            await db.execute(text(create_test_table_sql))
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚½ì… (100ê°œ ì •ë„)
            print("   í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚½ì… ì¤‘...")
            for i in range(100):
                # ëœë¤ ë²¡í„° ìƒì„±
                vec = [random.uniform(-1, 1) for _ in range(128)]
                # ì •ê·œí™”
                norm = sum(x**2 for x in vec) ** 0.5
                if norm > 0:
                    vec = [x / norm for x in vec]
                
                # ë²¡í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                vec_str = "[" + ",".join(map(str, vec)) + "]"
                insert_sql = "INSERT INTO test_hnsw (embedding) VALUES (:embedding)"
                await db.execute(text(insert_sql), {"embedding": vec_str})
            
            await db.commit()
            print(f"   âœ… 100ê°œ í…ŒìŠ¤íŠ¸ ë²¡í„° ì‚½ì… ì™„ë£Œ")
            
            # HNSW ì¸ë±ìŠ¤ ìƒì„±
            print("   HNSW ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
            start_time = time.time()
            
            create_index_sql = """
                CREATE INDEX test_hnsw_idx 
                ON test_hnsw 
                USING hnsw (embedding vector_cosine_ops)
                WITH (m = 16, ef_construction = 64)
            """
            
            await db.execute(text(create_index_sql))
            await db.commit()
            
            index_creation_time = time.time() - start_time
            print(f"   âœ… HNSW ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ ({index_creation_time:.2f}ì´ˆ)")
            
            # 3. ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            print("3. ì¸ë±ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
            
            # ef_search ì„¤ì •
            await db.execute(text("SET hnsw.ef_search = 40"))
            
            query_vec = [random.uniform(-1, 1) for _ in range(128)]
            norm = sum(x**2 for x in query_vec) ** 0.5
            if norm > 0:
                query_vec = [x / norm for x in query_vec]
            
            # ì¿¼ë¦¬ ë²¡í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            query_vec_str = "[" + ",".join(map(str, query_vec)) + "]"
            
            # ì—¬ëŸ¬ ë²ˆ ê²€ìƒ‰í•´ì„œ í‰ê·  ì‹œê°„ ì¸¡ì •
            search_times = []
            for _ in range(10):
                start_time = time.time()
                
                search_sql = """
                    SELECT id, 1 - (embedding <=> :query_vector) as similarity
                    FROM test_hnsw 
                    ORDER BY embedding <=> :query_vector
                    LIMIT 5
                """
                
                result = await db.execute(text(search_sql), {"query_vector": query_vec_str})
                rows = result.fetchall()
                
                search_time = (time.time() - start_time) * 1000
                search_times.append(search_time)
            
            avg_search_time = sum(search_times) / len(search_times)
            print(f"   í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time:.2f}ms (10íšŒ í‰ê· )")
            print(f"   ê²€ìƒ‰ëœ ê²°ê³¼ ìˆ˜: {len(rows)}")
            
            return {
                "index_creation_time": index_creation_time,
                "avg_search_time": avg_search_time,
                "data_count": 100
            }
            
    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

async def test_optimized_service():
    """ìµœì í™”ëœ ë²¡í„° ì €ì¥ì†Œ ì„œë¹„ìŠ¤ ì‹¤ì œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ìµœì í™”ëœ ë²¡í„° ì €ì¥ì†Œ ì„œë¹„ìŠ¤ ì‹¤ì œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        from services.optimized_vector_store import OptimizedVectorStoreService, IndexConfig
        from services.database import get_async_session
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        index_config = IndexConfig(m=16, ef_construction=64, ef_search=40)
        service = OptimizedVectorStoreService(
            embedding_model="test-real-embedding",
            index_config=index_config
        )
        
        async with get_async_session() as db:
            # 1. ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì‹¤ì œ ì‹¤í–‰
            print("1. ì‹¤ì œ ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¶„ì„...")
            
            analysis_result = await service.analyze_index_performance(db)
            
            if "error" not in analysis_result:
                print("   âœ… ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì„±ê³µ")
                
                table_perf = analysis_result.get("table_performance", {})
                for table_name, perf_data in table_perf.items():
                    if "error" not in perf_data:
                        print(f"     {table_name}:")
                        print(f"       - í…Œì´ë¸” í¬ê¸°: {perf_data.get('table_size', 'N/A')}")
                        print(f"       - ì¸ë±ìŠ¤ í¬ê¸°: {perf_data.get('index_size', 'N/A')}")
                        print(f"       - ë ˆì½”ë“œ ìˆ˜: {perf_data.get('row_count', 'N/A')}")
                        print(f"       - ì¸ë±ìŠ¤ ì¡´ì¬: {perf_data.get('index_exists', 'N/A')}")
            else:
                print(f"   âŒ ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {analysis_result['error']}")
            
            # 2. ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
            print("2. ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±...")
            
            recommendations = service.get_optimization_recommendations()
            print(f"   ìƒì„±ëœ ê¶Œì¥ì‚¬í•­: {len(recommendations)}ê°œ")
            
            for i, rec in enumerate(recommendations, 1):
                print(f"     {i}. {rec}")
            
            return True
            
    except Exception as e:
        print(f"âŒ ìµœì í™”ëœ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

async def main():
    """ë©”ì¸ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ì‹¤ì œ pgvector ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 70)
    
    test_results = {}
    
    # 1. ë²¡í„° ì—°ì‚° í…ŒìŠ¤íŠ¸
    vector_result = await test_vector_operations()
    test_results["vector_operations"] = vector_result
    
    if vector_result:
        # 2. ì¸ë±ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
        index_result = await test_index_creation()
        test_results["index_creation"] = index_result
        
        # 3. ìµœì í™”ëœ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
        service_result = await test_optimized_service()
        test_results["optimized_service"] = service_result
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    
    for test_name, result in test_results.items():
        status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
        
        if test_name == "index_creation" and isinstance(result, dict):
            print(f"  - ì¸ë±ìŠ¤ ìƒì„± ì‹œê°„: {result['index_creation_time']:.2f}ì´ˆ")
            print(f"  - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {result['avg_search_time']:.2f}ms")
            print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {result['data_count']}ê°œ")
    
    # ì „ì²´ ì„±ê³µ ì—¬ë¶€
    overall_success = all(test_results.values())
    print(f"\nì „ì²´ ì‹¤ì œ í…ŒìŠ¤íŠ¸: {'âœ… ì„±ê³µ' if overall_success else 'âŒ ì‹¤íŒ¨'}")
    
    if overall_success:
        print("\nğŸ‰ ëª¨ë“  ì‹¤ì œ pgvector ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ ì¼ë¶€ ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    return overall_success

if __name__ == "__main__":
    asyncio.run(main())
