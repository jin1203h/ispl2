"""
Task 3.5 Markdown ë³€í™˜ ë° êµ¬ì¡° ë³´ì¡´ í…ŒìŠ¤íŠ¸
"""
import asyncio
import os
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

from dotenv import load_dotenv

from agents.markdown_processor import MarkdownProcessorAgent
from agents.base import DocumentProcessingState, ProcessingStatus

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class MarkdownProcessingReport:
    """Markdown ë³€í™˜ ì²˜ë¦¬ ê²°ê³¼ ë³´ê³ ì„œ"""

    def __init__(self, test_pdf_path: str):
        self.test_pdf_path = test_pdf_path
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.report_data = {
            "metadata": {
                "test_file": test_pdf_path,
                "timestamp": self.timestamp,
                "test_type": "markdown_conversion_analysis"
            },
            "pdf_info": {},
            "conversion_stats": {},
            "quality_validation": {},
            "output_files": {},
            "overall_status": "FAILED",
            "error_message": None
        }
        self.console_output = []

    def log_console(self, message: str):
        """ì½˜ì†” ì¶œë ¥ì„ ë¡œê·¸ì— ì €ì¥"""
        self.console_output.append(message)
        print(message)

    def set_pdf_info(self, total_pages: int, file_size: str):
        """PDF ê¸°ë³¸ ì •ë³´ ì„¤ì •"""
        self.report_data["pdf_info"] = {
            "total_pages": total_pages,
            "file_size": file_size,
            "file_exists": os.path.exists(self.test_pdf_path)
        }

    def set_conversion_stats(self, stats: Dict[str, Any]):
        """ë³€í™˜ í†µê³„ ì„¤ì •"""
        self.report_data["conversion_stats"] = stats

    def set_quality_validation(self, validation: Dict[str, Any]):
        """í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ ì„¤ì •"""
        self.report_data["quality_validation"] = validation

    def set_output_files(self, output_info: Dict[str, Any]):
        """ì¶œë ¥ íŒŒì¼ ì •ë³´ ì„¤ì •"""
        self.report_data["output_files"] = output_info

    def set_overall_status(self, status: ProcessingStatus, error_message: str = None):
        """ì „ì²´ ì²˜ë¦¬ ìƒíƒœ ì„¤ì •"""
        self.report_data["overall_status"] = status.value
        self.report_data["error_message"] = error_message

    def save_reports(self):
        """ë³´ê³ ì„œë“¤ì„ íŒŒì¼ë¡œ ì €ì¥"""
        reports_dir = Path("reports/markdown_conversion")
        reports_dir.mkdir(parents=True, exist_ok=True)

        base_filename = f"markdown_conversion_report_{self.timestamp}"

        # 1. JSON ìƒì„¸ ë³´ê³ ì„œ ì €ì¥
        json_file = reports_dir / f"{base_filename}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            def json_serializable(obj):
                """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
                if hasattr(obj, 'value'):  # Enum ê°ì²´
                    return obj.value
                if isinstance(obj, dict):
                    return {k: json_serializable(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [json_serializable(item) for item in obj]
                elif hasattr(obj, '__dict__'):
                    return json_serializable(obj.__dict__)
                elif obj is None or (hasattr(obj, '__ne__') and obj != obj):  # NaN ì²´í¬
                    return None
                else:
                    try:
                        json.dumps(obj)  # ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
                        return obj
                    except (TypeError, ValueError):
                        return str(obj)

            serializable_data = json_serializable(self.report_data)
            json.dump(serializable_data, f, indent=2, ensure_ascii=False)

        # 2. í…ìŠ¤íŠ¸ ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
        txt_file = reports_dir / f"{base_filename}_summary.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("Markdown ë³€í™˜ ë° êµ¬ì¡° ë³´ì¡´ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"ğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {self.test_pdf_path}\n")
            f.write(f"ğŸ• í…ŒìŠ¤íŠ¸ ì‹œê°„: {self.timestamp}\n")
            f.write(f"âœ… ì „ì²´ ìƒíƒœ: {self.report_data['overall_status']}\n")
            if self.report_data['error_message']:
                f.write(f"âŒ ì˜¤ë¥˜ ë©”ì‹œì§€: {self.report_data['error_message']}\n")
            f.write("\n")

            f.write("ğŸ“– PDF ê¸°ë³¸ ì •ë³´:\n")
            for k, v in self.report_data["pdf_info"].items():
                f.write(f"   - {k}: {v}\n")
            f.write("\n")

            f.write("ğŸ“Š ë³€í™˜ í†µê³„:\n")
            for k, v in self.report_data["conversion_stats"].items():
                f.write(f"   - {k}: {v}\n")
            f.write("\n")

            f.write("ğŸ” í’ˆì§ˆ ê²€ì¦ ê²°ê³¼:\n")
            quality = self.report_data["quality_validation"]
            if quality:
                f.write(f"   - ì „ì²´ í†µê³¼: {quality.get('overall_passed', False)}\n")
                f.write(f"   - ì ìˆ˜: {quality.get('score', 0):.1f}ì \n")
                if quality.get('issues'):
                    f.write("   - ë¬¸ì œì :\n")
                    for issue in quality['issues']:
                        f.write(f"     * {issue}\n")
                
                f.write("   - ì„¸ë¶€ ê²°ê³¼:\n")
                for test_name, result in quality.get('detailed_results', {}).items():
                    status = "âœ…" if result['passed'] else "âŒ"
                    f.write(f"     {status} {result['description']}: {result['score']}\n")
            f.write("\n")

            f.write("ğŸ“ ì¶œë ¥ íŒŒì¼:\n")
            for k, v in self.report_data["output_files"].items():
                f.write(f"   - {k}: {v}\n")
            f.write("\n")

            f.write("=" * 80 + "\n")
            f.write("ì½˜ì†” ì¶œë ¥ ë¡œê·¸:\n")
            f.write("=" * 80 + "\n")
            for line in self.console_output:
                f.write(line + "\n")

        # 3. ì½˜ì†” ë¡œê·¸ íŒŒì¼ ì €ì¥
        log_file = reports_dir / f"{base_filename}_console.log"
        with open(log_file, 'w', encoding='utf-8') as f:
            for line in self.console_output:
                f.write(line + "\n")

        return {"json_report": str(json_file), "txt_summary": str(txt_file), "console_log": str(log_file)}

def create_sample_processed_chunks() -> List[Dict[str, Any]]:
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì²˜ë¦¬ëœ ì²­í¬ ìƒì„±"""
    return [
        {
            "text": "ë³´í—˜ì•½ê´€ ì œ1ì¥ ì´ì¹™",
            "metadata": {
                "chunk_index": 0,
                "page_number": 1,
                "chunk_type": "text",
                "source": "text_extraction",
                "font_size": 16,
                "bbox": [100, 700, 400, 720]
            }
        },
        {
            "text": "ì œ1ì¡° (ëª©ì ) ì´ ì•½ê´€ì€ ë³´í—˜íšŒì‚¬ì™€ ë³´í—˜ê³„ì•½ì ê°„ì˜ ê¶Œë¦¬ì™€ ì˜ë¬´ë¥¼ ê·œì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.",
            "metadata": {
                "chunk_index": 1,
                "page_number": 1,
                "chunk_type": "text",
                "source": "text_extraction",
                "font_size": 12,
                "bbox": [100, 650, 500, 680]
            }
        },
        {
            "text": "ì œ2ì¡° (ì •ì˜) ì´ ì•½ê´€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ì •ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n1. ë³´í—˜ê³„ì•½ì: ë³´í—˜íšŒì‚¬ì™€ ë³´í—˜ê³„ì•½ì„ ì²´ê²°í•˜ëŠ” ì\n2. í”¼ë³´í—˜ì: ë³´í—˜ì‚¬ê³ ì˜ ëŒ€ìƒì´ ë˜ëŠ” ì",
            "metadata": {
                "chunk_index": 2,
                "page_number": 1,
                "chunk_type": "text",
                "source": "text_extraction",
                "font_size": 12,
                "bbox": [100, 580, 500, 640]
            }
        },
        {
            "text": "",
            "metadata": {
                "chunk_index": 3,
                "page_number": 2,
                "chunk_type": "table",
                "source": "table_extraction",
                "table_data": [
                    ["êµ¬ë¶„", "ë³´ì¥ë‚´ìš©", "ë³´í—˜ê¸ˆì•¡"],
                    ["ìƒí•´ì‚¬ë§", "ìƒí•´ë¡œ ì¸í•œ ì‚¬ë§ ì‹œ", "1ì–µì›"],
                    ["ìƒí•´í›„ìœ ì¥í•´", "ìƒí•´ë¡œ ì¸í•œ í›„ìœ ì¥í•´ ì‹œ", "ì¥í•´ì •ë„ì— ë”°ë¼"],
                    ["ì§ˆë³‘ì‚¬ë§", "ì§ˆë³‘ìœ¼ë¡œ ì¸í•œ ì‚¬ë§ ì‹œ", "5ì²œë§Œì›"]
                ]
            }
        },
        {
            "text": "ë³´í—˜ ê°€ì… ì ˆì°¨ ì•ˆë‚´ ì´ë¯¸ì§€",
            "metadata": {
                "chunk_index": 4,
                "page_number": 3,
                "chunk_type": "image",
                "source": "image_extraction",
                "image_index": 0,
                "image_analysis": {
                    "quality": "good",
                    "image_type": "diagram",
                    "confidence": 0.85
                },
                "image_data": b"dummy_image_data"
            }
        },
        {
            "text": "* ì£¼ì˜ì‚¬í•­: ë³´í—˜ë£Œ ë‚©ì…ì´ ì—°ì²´ë  ê²½ìš° ë³´í—˜ê³„ì•½ì´ í•´ì§€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "metadata": {
                "chunk_index": 5,
                "page_number": 3,
                "chunk_type": "text",
                "source": "text_extraction",
                "font_size": 10,
                "bbox": [100, 200, 450, 220]
            }
        }
    ]

async def test_markdown_conversion():
    """Task 3.5 Markdown ë³€í™˜ ë° êµ¬ì¡° ë³´ì¡´ í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("Task 3.5: Markdown ë³€í™˜ ë° êµ¬ì¡° ë³´ì¡´ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)

    test_pdf_path = "uploads/pdf/test_policy.pdf"
    report = MarkdownProcessingReport(test_pdf_path)
    report.log_console("ğŸ“„ í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: " + test_pdf_path)

    # PDF ì •ë³´ ì„¤ì • (ì‹¤ì œ íŒŒì¼ì´ ì—†ì–´ë„ í…ŒìŠ¤íŠ¸ ì§„í–‰)
    if os.path.exists(test_pdf_path):
        file_size_mb = os.path.getsize(test_pdf_path) / (1024 * 1024)
        report.set_pdf_info(10, f"{file_size_mb:.2f} MB")
        report.log_console(f"ğŸ“– íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")
    else:
        report.set_pdf_info(10, "ìƒ˜í”Œ ë°ì´í„°")
        report.log_console("ğŸ“– ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ ì§„í–‰")

    # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_chunks = create_sample_processed_chunks()
    report.log_console(f"ğŸ“¦ í…ŒìŠ¤íŠ¸ ì²­í¬ ìƒì„±: {len(sample_chunks)}ê°œ")

    initial_state: DocumentProcessingState = {
        "file_path": test_pdf_path,
        "policy_id": 1,
        "file_name": os.path.basename(test_pdf_path),
        "current_step": "markdown_conversion",
        "status": ProcessingStatus.PENDING.value,
        "error_message": None,
        "processed_chunks": sample_chunks,
        "total_chunks": len(sample_chunks),
        "pdf_analysis": {
            "total_pages": 3,
            "document_type": "insurance_policy",
            "quality_score": 85.5,
            "processing_strategy": "standard"
        },
        "text_processing_stats": {
            "total_words": 150,
            "total_articles": 2
        }
    }

    agent = MarkdownProcessorAgent()

    try:
        report.log_console("\nğŸ”„ Markdown ë³€í™˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
        final_state = await agent.process(initial_state)

        # ê²°ê³¼ ë¶„ì„
        status = ProcessingStatus(final_state["status"])
        report.set_overall_status(status, final_state.get("error_message"))

        if "markdown_processing_stats" in final_state:
            report.set_conversion_stats(final_state["markdown_processing_stats"])

        if "quality_validation" in final_state:
            report.set_quality_validation(final_state["quality_validation"])

        # ì¶œë ¥ íŒŒì¼ ì •ë³´
        output_info = {
            "markdown_file": final_state.get("markdown_file_path"),
            "markdown_length": len(final_state.get("markdown_content", "")),
            "extracted_images": len(final_state.get("extracted_images", []))
        }
        report.set_output_files(output_info)

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        summary = agent.get_conversion_summary(final_state)
        
        report.log_console("\n" + "=" * 60)
        report.log_console("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        report.log_console("=" * 60)
        report.log_console(f"ë³€í™˜ ìƒíƒœ: {summary.get('conversion_status')}")
        report.log_console(f"ë³€í™˜ëœ ì²­í¬ ìˆ˜: {summary.get('total_chunks_converted')}")
        report.log_console(f"Markdown ê¸¸ì´: {summary.get('markdown_length')} ë¬¸ì")
        report.log_console(f"ì¶”ì¶œëœ ì´ë¯¸ì§€: {summary.get('extracted_images_count')}ê°œ")
        report.log_console(f"ì²˜ë¦¬ ì‹œê°„: {summary.get('processing_time')}")

        report.log_console("\nğŸ“Š í’ˆì§ˆ ë©”íŠ¸ë¦­:")
        quality_metrics = summary.get('quality_metrics', {})
        for metric, value in quality_metrics.items():
            report.log_console(f"   - {metric}: {value}")

        report.log_console("\nğŸ” í’ˆì§ˆ ê²€ì¦:")
        quality_validation = summary.get('quality_validation', {})
        report.log_console(f"   - ì „ì²´ í†µê³¼: {quality_validation.get('ì „ì²´ í†µê³¼')}")
        report.log_console(f"   - ì ìˆ˜: {quality_validation.get('ì ìˆ˜')}")
        
        issues = quality_validation.get('ë¬¸ì œì ', [])
        if issues:
            report.log_console("   - ë¬¸ì œì :")
            for issue in issues:
                report.log_console(f"     * {issue}")

        # Markdown ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        if final_state.get("markdown_content"):
            markdown_preview = final_state["markdown_content"][:500]
            report.log_console(f"\nğŸ“ Markdown ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
            report.log_console("-" * 40)
            report.log_console(markdown_preview)
            if len(final_state["markdown_content"]) > 500:
                report.log_console("...")
            report.log_console("-" * 40)

        # ë³´ê³ ì„œ ì €ì¥
        report.log_console("\nğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì¤‘...")
        saved_files = report.save_reports()
        report.log_console("âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ!")
        report.log_console(f"   - JSON ìƒì„¸ ë³´ê³ ì„œ: {saved_files['json_report']}")
        report.log_console(f"   - TXT ìš”ì•½ ë³´ê³ ì„œ: {saved_files['txt_summary']}")
        report.log_console(f"   - ì½˜ì†” ë¡œê·¸: {saved_files['console_log']}")

    except Exception as e:
        error_msg = f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
        logger.error(error_msg, exc_info=True)
        report.log_console(f"âŒ {error_msg}")
        report.set_overall_status(ProcessingStatus.FAILED, error_msg)
        report.save_reports()

    logger.info("\n" + "=" * 60)
    logger.info("Task 3.5 í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("=" * 60)

if __name__ == "__main__":
    asyncio.run(test_markdown_conversion())

