"""
LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
Task 5.4 ê²€ì¦ì„ ìœ„í•œ ì¢…í•© í…ŒìŠ¤íŠ¸
"""
import asyncio
import logging
import time
from typing import List, Dict, Any
import sys
import os

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.answer_service import (
    RAGAnswerService, AnswerConfig, GeneratedAnswer, LLMProvider
)
from services.result_service import ProcessedResult
from services.advanced_search_engine import SearchResult
from agents.query_processor import InsuranceQueryProcessor, ProcessedQuery

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AnswerServiceTest:
    """ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.service = RAGAnswerService()
        self.query_processor = InsuranceQueryProcessor()
        
    def create_mock_processed_results(self, count: int = 5) -> List[ProcessedResult]:
        """Mock í›„ì²˜ë¦¬ëœ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±"""
        mock_results = []
        
        # ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë³´í—˜ ì •ë³´
        insurance_data = [
            {
                "text": "ì•”ë³´í—˜ì€ ì•” ì§„ë‹¨ ì‹œ ì§„ë‹¨ê¸ˆì„ ì§€ê¸‰í•˜ëŠ” ë³´í—˜ìƒí’ˆì…ë‹ˆë‹¤. ê°€ì… ì—°ë ¹ì€ ë§Œ 15ì„¸ë¶€í„° 65ì„¸ê¹Œì§€ì´ë©°, ê±´ê°•ê³ ì§€ì„œ ì‘ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤. 90ì¼ê°„ì˜ ë©´ì±…ê¸°ê°„ì´ ì ìš©ë˜ë©°, ì¼ë°˜ì•” 2ì²œë§Œì›, ê³ ì•¡ì¹˜ë£Œë¹„ì•” 4ì²œë§Œì›, ì†Œì•¡ì¹˜ë£Œë¹„ì•” 1ì²œë§Œì›ì„ ë³´ì¥í•©ë‹ˆë‹¤.",
                "product": "ë¬´ë°°ë‹¹ ì›ë”í”Œ ì•”ë³´í—˜",
                "company": "ì‚¼ì„±ìƒëª…",
                "category": "ìƒëª…ë³´í—˜"
            },
            {
                "text": "ë³´í—˜ë£ŒëŠ” í”¼ë³´í—˜ìì˜ ë‚˜ì´, ì„±ë³„, ê±´ê°•ìƒíƒœì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ì›”ë‚© ê¸°ì¤€ìœ¼ë¡œ 30ì„¸ ë‚¨ì„±ì˜ ê²½ìš° ì›” 3ë§Œì›ë¶€í„° ì‹œì‘ë˜ë©°, ì—°ë‚© ì‹œ í• ì¸í˜œíƒì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³´í—˜ë£Œ ë‚©ì…ê¸°ê°„ì€ 10ë…„, 15ë…„, 20ë…„ ì¤‘ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "product": "ë¬´ë°°ë‹¹ ì›ë”í”Œ ì•”ë³´í—˜",
                "company": "ì‚¼ì„±ìƒëª…",
                "category": "ìƒëª…ë³´í—˜"
            },
            {
                "text": "ì‹¬ì¥ì§ˆí™˜ë³´í—˜ì€ ê¸‰ì„±ì‹¬ê·¼ê²½ìƒ‰ì¦, ê´€ìƒë™ë§¥ìš°íšŒìˆ  ë“± ì‹¬ì¥ ê´€ë ¨ ì§ˆí™˜ì„ ë³´ì¥í•©ë‹ˆë‹¤. ì§„ë‹¨ ì¦‰ì‹œ ë³´í—˜ê¸ˆì´ ì§€ê¸‰ë˜ë©°, ì…ì›ë¹„ì™€ ìˆ˜ìˆ ë¹„ë„ ë³„ë„ë¡œ ë³´ì¥ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ì… ì‹œ ì‹¬í˜ˆê´€ê³„ ê²€ì§„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "product": "ì‹¬í˜ˆê´€ì§ˆí™˜ë³´í—˜",
                "company": "í˜„ëŒ€í•´ìƒ",
                "category": "ì†í•´ë³´í—˜"
            },
            {
                "text": "ì‹¤ì†ì˜ë£Œë³´í—˜ì€ ë³‘ì›ì—ì„œ ì‹¤ì œë¡œ ì§€ì¶œí•œ ì˜ë£Œë¹„ë¥¼ ë³´ì¥í•˜ëŠ” ìƒí’ˆì…ë‹ˆë‹¤. ì—°ê°„ ë³´ì¥í•œë„ëŠ” 1ì–µì›ì´ë©°, ë³¸ì¸ë¶€ë‹´ê¸ˆ 10%ë¥¼ ì œì™¸í•œ 90%ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. ë¹„ê¸‰ì—¬ í•­ëª©ë„ ì—°ê°„ 2ì²œë§Œì›ê¹Œì§€ ë³´ì¥ë©ë‹ˆë‹¤.",
                "product": "ì‹¤ì†ì˜ë£Œë³´í—˜",
                "company": "KBì†í•´ë³´í—˜",
                "category": "ì†í•´ë³´í—˜"
            },
            {
                "text": "ì¹˜ì•„ë³´í—˜ì€ ì¹˜ê³¼ ì¹˜ë£Œë¹„ ë¶€ë‹´ì„ ëœì–´ì£¼ëŠ” ì „ë¬¸ ë³´í—˜ìƒí’ˆì…ë‹ˆë‹¤. ë³´ì¡´ì¹˜ë£Œ, ë³´ì² ì¹˜ë£Œ, ì„í”Œë€íŠ¸ ë“±ì„ ë³´ì¥í•˜ë©°, ëŒ€ê¸°ê¸°ê°„ì´ ì ìš©ë©ë‹ˆë‹¤. ë³´ì¡´ì¹˜ë£ŒëŠ” 90ì¼, ë³´ì² ì¹˜ë£ŒëŠ” 1ë…„, ì„í”Œë€íŠ¸ëŠ” 2ë…„ì˜ ëŒ€ê¸°ê¸°ê°„ì´ ìˆìŠµë‹ˆë‹¤.",
                "product": "ì¹˜ì•„ë³´í—˜",
                "company": "DBì†í•´ë³´í—˜",
                "category": "ì†í•´ë³´í—˜"
            }
        ]
        
        for i in range(min(count, len(insurance_data))):
            data = insurance_data[i]
            
            # SearchResult ìƒì„±
            search_result = SearchResult(
                embedding_id=i + 1,
                policy_id=100 + i,
                chunk_text=data["text"],
                chunk_index=i,
                product_name=data["product"],
                company=data["company"],
                category=data["category"],
                vector_score=0.9 - (i * 0.1),
                keyword_score=0.8 - (i * 0.1),
                hybrid_score=0.85 - (i * 0.1),
                final_score=0.85 - (i * 0.1),
                model="text-embedding-3-large",
                created_at="2024-09-24T12:00:00",
                relevance_reason="Mock í…ŒìŠ¤íŠ¸ ê²°ê³¼"
            )
            
            # ProcessedResult ìƒì„±
            processed_result = ProcessedResult(
                original_result=search_result,
                rerank_score=0.9 - (i * 0.1),
                diversity_score=1.0,
                context_quality=0.8,
                final_score=0.85 - (i * 0.1),
                extended_context=None,
                adjacent_chunks=None,
                deduplication_group=None
            )
            
            mock_results.append(processed_result)
        
        return mock_results
    
    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ¤– LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 70)
        
        try:
            # 1. ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
            print("\n1ï¸âƒ£ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
            await self.test_service_initialization()
            
            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸
            print("\n2ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸")
            await self.test_context_building()
            
            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
            print("\n3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸")
            await self.test_prompt_generation()
            
            # 4. Fallback ë‹µë³€ í…ŒìŠ¤íŠ¸
            print("\n4ï¸âƒ£ Fallback ë‹µë³€ í…ŒìŠ¤íŠ¸")
            await self.test_fallback_answer()
            
            # 5. í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸
            print("\n5ï¸âƒ£ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸")
            await self.test_quality_validation()
            
            # 6. ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
            print("\n6ï¸âƒ£ ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
            await self.test_comprehensive_scenarios()
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
        
        return True
    
    async def test_service_initialization(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        try:
            # ì„œë¹„ìŠ¤ í†µê³„ í™•ì¸
            stats = self.service.get_service_stats()
            
            print(f"LLM ì œê³µì: {stats['provider']}")
            print(f"ëª¨ë¸: {stats['model']}")
            print(f"í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ê°€ëŠ¥: {stats['client_available']}")
            print(f"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ: {stats['system_prompt_loaded']}")
            print(f"ì„¤ì •: ì˜¨ë„={stats['config']['temperature']}, ìµœëŒ€í† í°={stats['config']['max_tokens']}")
            
            # ê¸°ë³¸ ê²€ì¦
            initialization_checks = {
                "ì‹œìŠ¤í…œí”„ë¡¬í”„íŠ¸": stats['system_prompt_loaded'],
                "ì„¤ì •ë¡œë“œ": stats['config']['temperature'] > 0,
                "ëª¨ë¸ì„¤ì •": len(stats['model']) > 0
            }
            
            passed = sum(initialization_checks.values())
            total = len(initialization_checks)
            
            print(f"\nì´ˆê¸°í™” ê²€ì¦:")
            for check, result in initialization_checks.items():
                status = "âœ…" if result else "âŒ"
                print(f"  {check}: {status}")
            
            if passed >= total - 1:  # OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ì–´ë„ OK
                print("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                print("âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def test_context_building(self):
        """ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸"""
        try:
            # Mock ê²°ê³¼ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            mock_results = self.create_mock_processed_results(3)
            config = AnswerConfig()
            
            context = self.service._build_context(mock_results, config)
            
            print(f"ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)}ì")
            print(f"ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
            print(f"{context[:200]}...")
            
            # ì»¨í…ìŠ¤íŠ¸ ê²€ì¦
            context_checks = {
                "ê¸¸ì´ì ì ˆ": 100 < len(context) < config.max_context_length,
                "ì¶œì²˜í¬í•¨": "[ì¶œì²˜" in context,
                "ë‚´ìš©í¬í•¨": any(result.original_result.product_name in context for result in mock_results),
                "êµ¬ì¡°ì ": context.count("[ì¶œì²˜") >= 2
            }
            
            print(f"\nì»¨í…ìŠ¤íŠ¸ ê²€ì¦:")
            passed = 0
            for check, result in context_checks.items():
                status = "âœ…" if result else "âŒ"
                print(f"  {check}: {status}")
                if result:
                    passed += 1
            
            if passed >= 3:
                print("âœ… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                print("âŒ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def test_prompt_generation(self):
        """í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
        try:
            # í…ŒìŠ¤íŠ¸ ì§ˆì˜
            test_query = "ì•”ë³´í—˜ ê°€ì…ì¡°ê±´ì´ ê¶ê¸ˆí•´ìš”"
            processed_query = await self.query_processor.preprocess_query(test_query)
            
            # Mock ì»¨í…ìŠ¤íŠ¸
            mock_context = """[ì¶œì²˜ 1] ë¬´ë°°ë‹¹ ì›ë”í”Œ ì•”ë³´í—˜ - ì‚¼ì„±ìƒëª…
ì•”ë³´í—˜ ê°€ì…ì¡°ê±´: ë§Œ 15ì„¸~65ì„¸, ê±´ê°•ê³ ì§€ì„œ ì‘ì„± í•„ìš”, 90ì¼ ë©´ì±…ê¸°ê°„

[ì¶œì²˜ 2] KB ì•”ë³´í—˜í”ŒëŸ¬ìŠ¤ - KBì†í•´ë³´í—˜
ì•”ë³´í—˜ì€ ì§„ë‹¨ê¸ˆ, ìˆ˜ìˆ ë¹„, ì…ì›ë¹„ë¥¼ ë³´ì¥í•˜ëŠ” ì¢…í•©ì ì¸ ìƒí’ˆì…ë‹ˆë‹¤."""
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.service._build_rag_prompt(processed_query, mock_context)
            
            print(f"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ì")
            print(f"í”„ë¡¬í”„íŠ¸ êµ¬ì¡°:")
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ í™•ì¸
            prompt_components = {
                "ë³´í—˜ì•½ê´€ì •ë³´": "<ë³´í—˜ì•½ê´€ ì •ë³´>" in prompt,
                "ê³ ê°ì§ˆë¬¸": "<ê³ ê° ì§ˆë¬¸>" in prompt,
                "ì§ˆë¬¸ë‚´ìš©": test_query in prompt,
                "ì˜ë„ì •ë³´": "ì˜ë„:" in prompt,
                "í‚¤ì›Œë“œ": "í‚¤ì›Œë“œ:" in prompt,
                "ë‹µë³€í˜•ì‹": "## ë‹µë³€" in prompt
            }
            
            passed = 0
            for component, found in prompt_components.items():
                status = "âœ…" if found else "âŒ"
                print(f"  {component}: {status}")
                if found:
                    passed += 1
            
            if passed >= 5:
                print("âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                print("âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def test_fallback_answer(self):
        """Fallback ë‹µë³€ í…ŒìŠ¤íŠ¸"""
        try:
            # í…ŒìŠ¤íŠ¸ ì§ˆì˜
            test_query = await self.query_processor.preprocess_query("ë³´í—˜ë£Œ ê³„ì‚° ë°©ë²•")
            
            # ê²°ê³¼ ìˆëŠ” ê²½ìš°
            mock_results = self.create_mock_processed_results(2)
            fallback_answer = self.service._generate_fallback_answer(test_query, mock_results)
            
            print(f"ê²°ê³¼ ìˆëŠ” ê²½ìš° Fallback ë‹µë³€:")
            print(f"{fallback_answer[:300]}...")
            
            # ê²°ê³¼ ì—†ëŠ” ê²½ìš°
            empty_results = []
            empty_answer = self.service._generate_fallback_answer(test_query, empty_results)
            
            print(f"\nê²°ê³¼ ì—†ëŠ” ê²½ìš° Fallback ë‹µë³€:")
            print(f"{empty_answer}")
            
            # Fallback ë‹µë³€ ê²€ì¦
            fallback_checks = {
                "ê²°ê³¼ìˆìŒ_ì ì ˆê¸¸ì´": 50 < len(fallback_answer) < 1000,
                "ê²°ê³¼ìˆìŒ_êµ¬ì¡°í™”": "1." in fallback_answer or "2." in fallback_answer,
                "ê²°ê³¼ì—†ìŒ_ì•ˆë‚´": "ë¬¸ì˜" in empty_answer,
                "ì •ì¤‘í•¨": "ì£„ì†¡" in empty_answer or "ë°”ëë‹ˆë‹¤" in empty_answer
            }
            
            print(f"\nFallback ë‹µë³€ ê²€ì¦:")
            passed = 0
            for check, result in fallback_checks.items():
                status = "âœ…" if result else "âŒ"
                print(f"  {check}: {status}")
                if result:
                    passed += 1
            
            if passed >= 3:
                print("âœ… Fallback ë‹µë³€ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                print("âŒ Fallback ë‹µë³€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ Fallback ë‹µë³€ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def test_quality_validation(self):
        """ë‹µë³€ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        try:
            # í…ŒìŠ¤íŠ¸ ì§ˆì˜
            test_query = await self.query_processor.preprocess_query("ì•”ë³´í—˜ ê°€ì…ì¡°ê±´ê³¼ ë³´í—˜ë£Œ")
            mock_results = self.create_mock_processed_results(3)
            
            # ë‹¤ì–‘í•œ í’ˆì§ˆì˜ ë‹µë³€ í…ŒìŠ¤íŠ¸
            test_answers = [
                {
                    "content": """## ë‹µë³€
ì•”ë³´í—˜ ê°€ì…ì¡°ê±´ì€ ë§Œ 15ì„¸ë¶€í„° 65ì„¸ê¹Œì§€ì´ë©°, ê±´ê°•ê³ ì§€ì„œ ì‘ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.

## ìƒì„¸ ì„¤ëª…
ë³´í—˜ë£ŒëŠ” ë‚˜ì´, ì„±ë³„, ê±´ê°•ìƒíƒœì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, 30ì„¸ ë‚¨ì„± ê¸°ì¤€ ì›” 3ë§Œì›ë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤. 90ì¼ê°„ì˜ ë©´ì±…ê¸°ê°„ì´ ì ìš©ë©ë‹ˆë‹¤.

## ì¶œì²˜
ë¬´ë°°ë‹¹ ì›ë”í”Œ ì•”ë³´í—˜ - ì‚¼ì„±ìƒëª…""",
                    "expected_quality": "high"
                },
                {
                    "content": "ì•”ë³´í—˜ì€ ì¢‹ì€ ìƒí’ˆì…ë‹ˆë‹¤.",
                    "expected_quality": "low"
                },
                {
                    "content": """ì•”ë³´í—˜ ê°€ì…ì¡°ê±´ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. 
ê°€ì… ì—°ë ¹ì€ ë§Œ 15ì„¸ë¶€í„° 65ì„¸ê¹Œì§€ì´ë©°, ê±´ê°•ê³ ì§€ì„œ ì‘ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.
ë³´í—˜ë£ŒëŠ” ì›” 3ë§Œì›ë¶€í„° ì‹œì‘ë˜ë©°, ì‚¼ì„±ìƒëª…ì˜ ë¬´ë°°ë‹¹ ì›ë”í”Œ ì•”ë³´í—˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.""",
                    "expected_quality": "medium"
                }
            ]
            
            print("ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ê²°ê³¼:")
            
            for i, test_case in enumerate(test_answers):
                quality_score = await self.service._validate_answer_quality(
                    test_case["content"], test_query, mock_results
                )
                
                print(f"  ë‹µë³€ {i+1} ({test_case['expected_quality']}): í’ˆì§ˆì ìˆ˜ {quality_score:.2f}")
            
            # í’ˆì§ˆ ê²€ì¦ ë¡œì§ í…ŒìŠ¤íŠ¸
            high_quality_answer = test_answers[0]["content"]
            quality_score = await self.service._validate_answer_quality(
                high_quality_answer, test_query, mock_results
            )
            
            if quality_score > 0.6:
                print("âœ… ë‹µë³€ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                print(f"âŒ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ì ìˆ˜: {quality_score:.2f})")
                
        except Exception as e:
            print(f"âŒ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def test_comprehensive_scenarios(self):
        """ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        try:
            # ë‹¤ì–‘í•œ ì§ˆì˜ ìœ í˜• í…ŒìŠ¤íŠ¸
            test_scenarios = [
                {
                    "query": "30ì„¸ ë‚¨ì„±ì´ ì•”ë³´í—˜ì— ê°€ì…í•˜ë ¤ë©´ ì–´ë–¤ ì¡°ê±´ì´ í•„ìš”í•œê°€ìš”?",
                    "intent": "search",
                    "expected_elements": ["ê°€ì…ì¡°ê±´", "ì—°ë ¹", "ê±´ê°•ê³ ì§€"]
                },
                {
                    "query": "ë³´í—˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
                    "intent": "calculate",
                    "expected_elements": ["ë³´í—˜ë£Œ", "3ë§Œì›", "ì›”ë‚©"]
                },
                {
                    "query": "ì•”ë³´í—˜ê³¼ ì‹¤ì†ì˜ë£Œë³´í—˜ì˜ ì°¨ì´ì ì€?",
                    "intent": "compare",
                    "expected_elements": ["ì°¨ì´", "ì•”ë³´í—˜", "ì‹¤ì†ì˜ë£Œë³´í—˜"]
                }
            ]
            
            print("ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸:")
            
            successful_scenarios = 0
            
            for i, scenario in enumerate(test_scenarios):
                print(f"\nì‹œë‚˜ë¦¬ì˜¤ {i+1}: {scenario['query']}")
                
                try:
                    # ì§ˆì˜ ì „ì²˜ë¦¬
                    processed_query = await self.query_processor.preprocess_query(scenario['query'])
                    
                    # Mock ê²€ìƒ‰ ê²°ê³¼
                    mock_results = self.create_mock_processed_results(3)
                    
                    # ë‹µë³€ ìƒì„± (Fallback ëª¨ë“œ)
                    start_time = time.time()
                    answer = await self.service.generate_answer(processed_query, mock_results)
                    generation_time = time.time() - start_time
                    
                    print(f"  ìƒì„±ì‹œê°„: {generation_time:.2f}ì´ˆ")
                    print(f"  í’ˆì§ˆì ìˆ˜: {answer.quality_score:.2f}")
                    print(f"  ì‹ ë¢°ë„: {answer.confidence:.2f}")
                    print(f"  ë‹µë³€ê¸¸ì´: {len(answer.content)}ì")
                    print(f"  ì¶œì²˜ê°œìˆ˜: {len(answer.sources)}ê°œ")
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦
                    scenario_checks = {
                        "ìƒì„±ì„±ê³µ": len(answer.content) > 0,
                        "ì ì ˆì‹œê°„": generation_time < 5.0,
                        "í’ˆì§ˆì ìˆ˜": answer.quality_score > 0.3,
                        "ì¶œì²˜í¬í•¨": len(answer.sources) > 0
                    }
                    
                    passed_checks = sum(scenario_checks.values())
                    
                    if passed_checks >= 3:
                        print(f"  âœ… ì‹œë‚˜ë¦¬ì˜¤ {i+1} ì„±ê³µ")
                        successful_scenarios += 1
                    else:
                        print(f"  âŒ ì‹œë‚˜ë¦¬ì˜¤ {i+1} ì‹¤íŒ¨")
                        
                except Exception as scenario_error:
                    print(f"  âŒ ì‹œë‚˜ë¦¬ì˜¤ {i+1} ì˜¤ë¥˜: {scenario_error}")
            
            # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
            success_rate = successful_scenarios / len(test_scenarios)
            print(f"\nì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ ì„±ê³µë¥ : {success_rate:.1%} ({successful_scenarios}/{len(test_scenarios)})")
            
            if success_rate >= 0.8:  # 80% ì´ìƒ
                print("âœ… ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                print("âŒ ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = AnswerServiceTest()
    
    try:
        success = await tester.run_all_tests()
        
        print("\n" + "=" * 70)
        if success:
            print("ğŸ‰ LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print("âœ… ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
            print("\nğŸ“‹ ê²€ì¦ëœ ê¸°ëŠ¥:")
            print("  - ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì„¤ì •")
            print("  - ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë° í”„ë¡¬í”„íŠ¸ ìƒì„±")
            print("  - Fallback ë‹µë³€ ìƒì„±")
            print("  - ë‹µë³€ í’ˆì§ˆ ê²€ì¦")
            print("  - ì¶œì²˜ ì¶”ì¶œ ë° ì¸ìš©")
            print("  - ë‹¤ì–‘í•œ ì§ˆì˜ ìœ í˜• ì²˜ë¦¬")
        else:
            print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        return success
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)

