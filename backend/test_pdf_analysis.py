#!/usr/bin/env python3
"""
Task 3.1: PDF í’ˆì§ˆ ë¶„ì„ ë° êµ¬ì¡° íŒŒì•… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

# .env íŒŒì¼ ë¡œë“œ (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

import asyncio
import sys
import os
import time
import json
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(__file__))

from agents.pdf_processor import PDFProcessorAgent
from agents.base import DocumentProcessingState, ProcessingStatus

async def test_pdf_analysis():
    """PDF ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Task 3.1: PDF í’ˆì§ˆ ë¶„ì„ ë° êµ¬ì¡° íŒŒì•… í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # PDF í”„ë¡œì„¸ì„œ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    pdf_processor = PDFProcessorAgent()
    
    # í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
    test_files = [
        "uploads/pdf/test_policy.pdf",
        "uploads/pdf/sample.pdf",
        "../frontend/public/sample.pdf"
    ]
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” PDF íŒŒì¼ ì°¾ê¸°
    test_file = None
    for file_path in test_files:
        if os.path.exists(file_path):
            test_file = file_path
            break
    
    if not test_file:
        print("âŒ í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ìœ„ì¹˜ ì¤‘ í•˜ë‚˜ì— PDF íŒŒì¼ì„ ë°°ì¹˜í•´ì£¼ì„¸ìš”:")
        for file_path in test_files:
            print(f"  - {file_path}")
        
        # ë”ë¯¸ PDF íŒŒì¼ ìƒì„± ì‹œë„
        print("\nğŸ“„ ë”ë¯¸ PDF íŒŒì¼ ìƒì„± ì‹œë„...")
        dummy_pdf = await create_dummy_pdf()
        if dummy_pdf:
            test_file = dummy_pdf
        else:
            return False
    
    print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_file}")
    
    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state: DocumentProcessingState = {
        "file_path": test_file,
        "policy_id": 999,
        "file_name": os.path.basename(test_file),
        "current_step": "initialized",
        "status": ProcessingStatus.PENDING.value,
        "error_message": None,
        "raw_content": None,
        "pdf_metadata": None,
        "extracted_text": None,
        "extracted_tables": None,
        "extracted_images": None,
        "processed_chunks": [],
        "total_chunks": 0,
        "processing_time": 0.0,
        "start_time": time.time(),
        "end_time": None,
        "next_node": None
    }
    
    print("\nğŸš€ PDF ë¶„ì„ ì‹œì‘...")
    start_time = time.time()
    
    # PDF ë¶„ì„ ì‹¤í–‰
    result_state = await pdf_processor.process(initial_state)
    
    processing_time = time.time() - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼ (ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ)")
    print("-" * 40)
    
    if result_state["status"] == ProcessingStatus.COMPLETED.value:
        print("âœ… ë¶„ì„ ì„±ê³µ!")
        
        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
        metadata = result_state.get("pdf_metadata", {})
        basic_info = metadata.get("basic_info", {})
        
        print(f"\nğŸ“‹ ê¸°ë³¸ ì •ë³´:")
        print(f"  - íŒŒì¼ëª…: {basic_info.get('title', 'ì œëª© ì—†ìŒ')}")
        print(f"  - í˜ì´ì§€ ìˆ˜: {basic_info.get('total_pages', 0)}")
        print(f"  - íŒŒì¼ í¬ê¸°: {basic_info.get('file_size', 0):,} bytes")
        print(f"  - ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {basic_info.get('total_text_chars', 0):,} ë¬¸ì")
        print(f"  - ì´ ì´ë¯¸ì§€ ìˆ˜: {basic_info.get('total_images', 0)}")
        
        # ë¬¸ì„œ ë¶„ë¥˜ ì •ë³´
        doc_classification = metadata.get("document_classification", {})
        print(f"\nğŸ“„ ë¬¸ì„œ ë¶„ë¥˜:")
        print(f"  - íƒ€ì…: {doc_classification.get('type', 'unknown')}")
        print(f"  - ì‹ ë¢°ë„: {doc_classification.get('confidence', 0):.2f}")
        
        # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if metadata.get("advanced_analysis_available", False):
            print(f"\nğŸ”¬ ê³ ê¸‰ ë¶„ì„ ê²°ê³¼:")
            
            quality = metadata.get("quality_assessment", {})
            print(f"  - ìŠ¤ìº” ë¬¸ì„œ ì—¬ë¶€: {'ì˜ˆ' if quality.get('is_likely_scan', False) else 'ì•„ë‹ˆì˜¤'}")
            print(f"  - OCR ê¶Œì¥: {'ì˜ˆ' if quality.get('ocr_recommended', False) else 'ì•„ë‹ˆì˜¤'}")
            
            structure = metadata.get("structure_elements", {})
            tables = structure.get("table_regions", [])
            images = structure.get("image_analysis", {})
            
            print(f"  - íƒì§€ëœ í‘œ ì˜ì—­: {len(tables)}ê°œ")
            print(f"  - ì´ë¯¸ì§€ ë¶„ì„: {images.get('total_images', 0)}ê°œ (ëŒ€í˜•: {images.get('large_images', 0)}ê°œ)")
        
        # ì²˜ë¦¬ ì „ëµ
        strategy = metadata.get("processing_recommendations", {})
        print(f"\nğŸ¯ ì²˜ë¦¬ ì „ëµ:")
        print(f"  - í…ìŠ¤íŠ¸ ì¶”ì¶œ: {strategy.get('text_extraction', 'unknown')}")
        print(f"  - OCR í•„ìš”: {'ì˜ˆ' if strategy.get('ocr_required', False) else 'ì•„ë‹ˆì˜¤'}")
        print(f"  - í‘œ ì¶”ì¶œ: {', '.join(strategy.get('table_extraction', []))}")
        print(f"  - ì´ë¯¸ì§€ ì²˜ë¦¬: {strategy.get('image_processing', 'basic')}")
        print(f"  - ìµœì í™” ë ˆë²¨: {strategy.get('optimization_level', 'standard')}")
        
        # í˜ì´ì§€ë³„ ë¶„ì„ (ì²˜ìŒ 3í˜ì´ì§€ë§Œ)
        pages_info = basic_info.get("pages_info", [])
        if pages_info:
            print(f"\nğŸ“„ í˜ì´ì§€ ë¶„ì„ (ì²˜ìŒ 3í˜ì´ì§€):")
            for page in pages_info[:3]:
                print(f"  í˜ì´ì§€ {page['page_number']}: "
                      f"í…ìŠ¤íŠ¸ {'âœ“' if page['has_text'] else 'âœ—'} | "
                      f"ì´ë¯¸ì§€ {page['image_count']}ê°œ | "
                      f"í¬ê¸° {page['width']:.0f}x{page['height']:.0f}")
        
        # êµ¬ì¡° ë¶„ì„ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
        output_file = "test_analysis_result.json"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result_state, f, ensure_ascii=False, indent=2, default=str)
            print(f"\nğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\nâš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return True
        
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨!")
        error_msg = result_state.get("error_message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        print(f"ì˜¤ë¥˜: {error_msg}")
        return False

async def create_dummy_pdf():
    """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ PDF íŒŒì¼ ìƒì„±"""
    try:
        # PyMuPDFë¡œ ê°„ë‹¨í•œ PDF ìƒì„±
        import fitz
        
        doc = fitz.open()  # ìƒˆ PDF ë¬¸ì„œ ìƒì„±
        page = doc.new_page()
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        text = """
        í…ŒìŠ¤íŠ¸ ë³´í—˜ì•½ê´€ ë¬¸ì„œ
        
        ì œ1ì¥ ì´ì¹™
        ì œ1ì¡° (ëª©ì ) ì´ ì•½ê´€ì€ ë³´í—˜ ê³„ì•½ì— ê´€í•œ ì‚¬í•­ì„ ê·œì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.
        
        ì œ2ì¡° (ì •ì˜) ì´ ì•½ê´€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ì •ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
        1. í”¼ë³´í—˜ì: ë³´í—˜ì˜ ëŒ€ìƒì´ ë˜ëŠ” ì‚¬ëŒ
        2. ë³´í—˜ê¸ˆ: ë³´í—˜ì‚¬ê³  ë°œìƒ ì‹œ ì§€ê¸‰í•˜ëŠ” ê¸ˆì•¡
        
        ì œ2ì¥ ë³´í—˜ê³„ì•½
        ì œ3ì¡° (ê³„ì•½ì˜ ì²´ê²°) ë³´í—˜ê³„ì•½ì€ ê³„ì•½ìì˜ ì²­ì•½ê³¼ íšŒì‚¬ì˜ ìŠ¹ë‚™ìœ¼ë¡œ ì„±ë¦½í•œë‹¤.
        """
        
        page.insert_text((50, 50), text, fontsize=12)
        
        # ì €ì¥
        os.makedirs("uploads/pdf", exist_ok=True)
        dummy_file = "uploads/pdf/test_dummy.pdf"
        doc.save(dummy_file)
        doc.close()
        
        print(f"âœ… ë”ë¯¸ PDF íŒŒì¼ ìƒì„±: {dummy_file}")
        return dummy_file
        
    except ImportError:
        print("âŒ PyMuPDFê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë”ë¯¸ PDFë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"âŒ ë”ë¯¸ PDF ìƒì„± ì‹¤íŒ¨: {e}")
        return None

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    success = await test_pdf_analysis()
    
    if success:
        print("\nğŸ‰ Task 3.1: PDF í’ˆì§ˆ ë¶„ì„ ë° êµ¬ì¡° íŒŒì•… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("âœ… ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
